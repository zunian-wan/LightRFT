


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lightrft.strategy.strategy_base &mdash; LightRFT v0.1.1 documentation</title>
  

  <link rel="shortcut icon" href="../../../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/readthedocs.css" type="text/css" />
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/LightRFT" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/LightZero" target="_blank">
                  <span class="dropdown-title">LightZero </span>
                  <p>OpenDILab Decision Monte Carlo Tree Search Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GenerativeRL" target="_blank">
                  <span class="dropdown-title">GenerativeRL </span>
                  <p>OpenDILab Generative AI Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start/index.html">Quick Start</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide &amp; Best Practices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../best_practice/index.html">Best Practices</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/utils/index.html">lightrft.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/datasets/index.html">lightrft.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/models/index.html">lightrft.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/strategy/index.html">lightrft.strategy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/trainer/index.html">lightrft.trainer</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>lightrft.strategy.strategy_base</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <h1>Source code for lightrft.strategy.strategy_base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">A module for implementing training strategies in deep learning, particularly for RLVR and RLHF.</span>

<span class="sd">This module provides base classes and utilities for different training strategies like DeepSpeed and FSDP.</span>
<span class="sd">It handles distributed training setup, model/optimizer preparation, checkpointing, and inference engine management.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">abc</span><span class="w"> </span><span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">contextlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">enum</span><span class="w"> </span><span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">easydict</span><span class="w"> </span><span class="kn">import</span> <span class="n">EasyDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">distributed</span> <span class="k">as</span> <span class="n">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.distributed.device_mesh</span><span class="w"> </span><span class="kn">import</span> <span class="n">init_device_mesh</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_scheduler</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.utils.distributed_util</span><span class="w"> </span><span class="kn">import</span> <span class="n">gather_inputs_object_for_inference</span><span class="p">,</span> <span class="n">create_sub_group</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.utils.broadcast_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">BroadcastManager</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.utils.data_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedSampler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.utils.parallel_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">SPDataProcessor</span><span class="p">,</span>
    <span class="n">get_sequence_parallel_group</span><span class="p">,</span>
    <span class="n">set_sequence_parallel_group</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.utils.statistic</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenLenAnalyser</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.sglang_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_sglang_engine_for_rollout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.vllm_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_vllm_engine_for_rollout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.strategy.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">StrategyConfig</span>

<span class="n">ModelOptimPair</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">Optimizer</span><span class="p">]</span>
<span class="n">ModelOrModelOptimPair</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">ModelOptimPair</span><span class="p">]</span>


<div class="viewcode-block" id="EngineStatus"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.EngineStatus">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">EngineStatus</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enum class for inference engine status.</span>

<span class="sd">    :cvar SLEEPED: Engine is in sleep mode</span>
<span class="sd">    :cvar WAKEUP: Engine is awake and ready</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">SLEEPED</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">WAKEUP</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="StrategyBase"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">StrategyBase</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for training strategies (DeepSpeed and FSDP).</span>

<span class="sd">    Provides common functionality for distributed training setup, model preparation,</span>
<span class="sd">    optimization, checkpointing, and inference engine management.</span>

<span class="sd">    :param seed: Random seed for reproducibility</span>
<span class="sd">    :type seed: int</span>
<span class="sd">    :param max_norm: Maximum gradient norm for clipping</span>
<span class="sd">    :type max_norm: float</span>
<span class="sd">    :param micro_train_batch_size: Batch size for each training step</span>
<span class="sd">    :type micro_train_batch_size: int</span>
<span class="sd">    :param train_batch_size: Total batch size for training</span>
<span class="sd">    :type train_batch_size: int</span>
<span class="sd">    :param args: Additional configuration arguments</span>
<span class="sd">    :type args: Any</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="StrategyBase.__init__"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.__init__">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>  <span class="c1"># pylint: disable=R0917</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_norm</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">micro_train_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">train_batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize strategy with common parameters.</span>

<span class="sd">        :param seed: Random seed for reproducibility</span>
<span class="sd">        :type seed: int</span>
<span class="sd">        :param max_norm: Maximum gradient norm for clipping</span>
<span class="sd">        :type max_norm: float</span>
<span class="sd">        :param micro_train_batch_size: Batch size for each training step</span>
<span class="sd">        :type micro_train_batch_size: int</span>
<span class="sd">        :param train_batch_size: Total batch size for training</span>
<span class="sd">        :type train_batch_size: int</span>
<span class="sd">        :param args: Additional configuration arguments</span>
<span class="sd">        :type args: Any (usually argparse.Namespace)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_norm</span> <span class="o">=</span> <span class="n">max_norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">micro_train_batch_size</span> <span class="o">=</span> <span class="n">micro_train_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">train_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

        <span class="c1"># Create config object for typed parameter access</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">StrategyConfig</span><span class="o">.</span><span class="n">from_args</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="k">if</span> <span class="n">args</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">StrategyConfig</span><span class="p">()</span>

        <span class="c1"># Use config object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adam_offload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">adam_offload</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zpg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">zpg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad_accum_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">grad_accum_dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">overlap_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">overlap_comm</span>

        <span class="c1"># inference (rollout) engine related</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">=</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">SLEEPED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_manager</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">time_steps</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_profile_step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># initialize distributed environment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setup_distributed</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">60</span><span class="p">))</span>
        <span class="c1"># NOTE: this group is not used by vllm, only used in strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">engine_mp_group</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine_dp_group</span> <span class="o">=</span> <span class="n">create_sub_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_tp_size</span><span class="p">)</span>

        <span class="c1"># initialize sequence parallel data processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sp_data_processor</span> <span class="o">=</span> <span class="n">SPDataProcessor</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">genlen_analyser</span> <span class="o">=</span> <span class="n">GenLenAnalyser</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">engine_dp_group</span><span class="p">,</span>
            <span class="n">plot_every</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">plot_every</span><span class="p">,</span>
            <span class="n">plot_out_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_tensorboard</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.set_seed"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.set_seed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set random seeds for reproducibility.</span>

<span class="sd">        :param seed: The random seed to use</span>
<span class="sd">        :type seed: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.setup_distributed"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.setup_distributed">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">setup_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">timedelta</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_gpu_per_node</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize distributed training environment.</span>

<span class="sd">        :param timeout: Maximum time to wait for initialization</span>
<span class="sd">        :type timeout: timedelta, optional</span>
<span class="sd">        :param num_gpu_per_node: Number of GPUs per node</span>
<span class="sd">        :type num_gpu_per_node: int</span>
<span class="sd">        :raises RuntimeError: If required environment variables are missing</span>
<span class="sd">        :raises ValueError: If unsupported engine type is specified</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="s2">&quot;LOCAL_RANK&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>  <span class="c1"># for slurm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="s2">&quot;RANK&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RANK&quot;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">%</span> <span class="n">num_gpu_per_node</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">engine_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span>

        <span class="n">enable_fsdp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">fsdp</span>

        <span class="k">if</span> <span class="n">enable_fsdp</span><span class="p">:</span>
            <span class="c1"># Initializes the distributed backend which will take care of sychronizing nodes/GPUs</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RANK&quot;</span><span class="p">])</span>
                <span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not find </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2"> in the torch environment&quot;</span><span class="p">)</span>

            <span class="c1"># initialize the default process group</span>
            <span class="n">host</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">,</span> <span class="s2">&quot;localhost&quot;</span><span class="p">)</span>
            <span class="n">port</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">,</span> <span class="s2">&quot;2222&quot;</span><span class="p">)</span>
            <span class="n">init_method</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;tcp://</span><span class="si">{</span><span class="n">host</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Init Distributed Env, init_method:</span><span class="si">{</span><span class="n">init_method</span><span class="si">}</span><span class="s2">, rank:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">, world_size:</span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2">, engine_type:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># noqa</span>
                <span class="p">)</span>
            <span class="c1"># TODO: unify the init_process_group for both vllm and sglang when stable version finished</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">):</span>
                <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
                    <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                    <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
                    <span class="c1"># here we set both cpu and cuda as backend, because we need to support</span>
                    <span class="c1"># both gpu and cpu training (e.g. FSDP and FSDP with cpu offload)</span>
                    <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;cpu:gloo,cuda:nccl&quot;</span><span class="p">,</span>
                    <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span>
                    <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported backend: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Initializes the distributed backend which will take care of sychronizing nodes/GPUs</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">):</span>
                <span class="n">deepspeed</span><span class="o">.</span><span class="n">init_distributed</span><span class="p">(</span><span class="n">dist_backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="n">timeout</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported backend: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accumulated_gradient</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">micro_train_batch_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">micro_train_batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;train_batch_size must be divisible by (micro_train_batch_size * world_size)</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;  train_batch_size:        </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;  micro_train_batch_size:  </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">micro_train_batch_size</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;  world_size:              </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;  Required: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size</span><span class="si">}</span><span class="s2"> % (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">micro_train_batch_size</span><span class="si">}</span><span class="s2"> * </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) == 0&quot;</span>
            <span class="p">)</span>
        <span class="c1"># initialize sequence parallel</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sp_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sp_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;sp_size should be even divided by world size.&quot;</span>
            <span class="n">dp_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sp_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sp_mesh_device</span> <span class="o">=</span> <span class="n">init_device_mesh</span><span class="p">(</span>
                <span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">mesh_shape</span><span class="o">=</span><span class="p">(</span><span class="n">dp_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sp_size</span><span class="p">),</span> <span class="n">mesh_dim_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dp&quot;</span><span class="p">,</span> <span class="s2">&quot;sp&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">set_sequence_parallel_group</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sp_mesh_device</span><span class="p">[</span><span class="s2">&quot;sp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_group</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Init Sequence Parallel, sp_size:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sp_size</span><span class="si">}</span><span class="s2">, </span><span class="se">\</span>
<span class="s2">                local_rank:</span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="n">get_sequence_parallel_group</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.create_optimizer"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.create_optimizer">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create optimizer for the model.</span>

<span class="sd">        :param model: The model to optimize</span>
<span class="sd">        :type model: nn.Module</span>
<span class="sd">        :param kwargs: Additional optimizer arguments</span>
<span class="sd">        :return: The created optimizer</span>
<span class="sd">        :rtype: optim.Optimizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.prepare"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.prepare">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="o">*</span><span class="n">models_or_model_optim_pairs</span><span class="p">:</span> <span class="n">ModelOrModelOptimPair</span><span class="p">,</span>
                <span class="n">is_rlhf</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ModelOrModelOptimPair</span><span class="p">],</span> <span class="n">ModelOrModelOptimPair</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare models and optimizers for training.</span>

<span class="sd">        :param models_or_model_optim_pairs: Models or (model, optimizer) pairs to prepare</span>
<span class="sd">        :param is_rlhf: Whether preparing for RLHF training</span>
<span class="sd">        :type is_rlhf: bool</span>
<span class="sd">        :return: Prepared models/optimizers</span>
<span class="sd">        :rtype: Union[List[ModelOrModelOptimPair], ModelOrModelOptimPair]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.backward"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.backward">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform backward pass.</span>

<span class="sd">        :param loss: The loss to backpropagate</span>
<span class="sd">        :type loss: torch.Tensor</span>
<span class="sd">        :param model: The model</span>
<span class="sd">        :type model: nn.Module</span>
<span class="sd">        :param optimizer: The optimizer</span>
<span class="sd">        :type optimizer: optim.Optimizer</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.optimizer_step"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.optimizer_step">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">optimizer_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Take optimizer step.</span>

<span class="sd">        :param optimizer: The optimizer</span>
<span class="sd">        :type optimizer: optim.Optimizer</span>
<span class="sd">        :param model: The model</span>
<span class="sd">        :type model: nn.Module</span>
<span class="sd">        :param scheduler: The learning rate scheduler</span>
<span class="sd">        :param name: Name for logging purposes</span>
<span class="sd">        :type name: str</span>
<span class="sd">        :param kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.setup_dataloader"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.setup_dataloader">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">setup_dataloader</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">replay_buffer</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">sampler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">consumed_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up data loader for training.</span>

<span class="sd">        :param replay_buffer: Dataset/replay buffer</span>
<span class="sd">        :param batch_size: Batch size</span>
<span class="sd">        :type batch_size: int</span>
<span class="sd">        :param pin_memory: Whether to pin memory</span>
<span class="sd">        :type pin_memory: bool</span>
<span class="sd">        :param shuffle: Whether to shuffle data</span>
<span class="sd">        :type shuffle: bool</span>
<span class="sd">        :param collate_fn: Function to collate samples</span>
<span class="sd">        :type collate_fn: Optional[Callable]</span>
<span class="sd">        :param drop_last: Whether to drop last incomplete batch</span>
<span class="sd">        :type drop_last: bool</span>
<span class="sd">        :param sampler: Custom sampler</span>
<span class="sd">        :param consumed_samples: Number of samples already consumed</span>
<span class="sd">        :type consumed_samples: int</span>
<span class="sd">        :return: Configured DataLoader</span>
<span class="sd">        :rtype: DataLoader</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">sampler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_replicas</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
            <span class="n">sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
                <span class="n">replay_buffer</span><span class="p">,</span>
                <span class="n">num_replicas</span><span class="o">=</span><span class="n">num_replicas</span><span class="p">,</span>
                <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
                <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
                <span class="n">consumed_samples</span><span class="o">=</span><span class="n">consumed_samples</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">replay_buffer</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
            <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.save_ckpt"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.save_ckpt">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_ckpt</span><span class="p">(</span>  <span class="c1"># pylint: disable=R0917, W0102</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">save_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">max_mem</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">client_state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_latest</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save training checkpoint with additional metadata.</span>

<span class="sd">        :param model: The model to save</span>
<span class="sd">        :param save_dir: Directory to save the checkpoint</span>
<span class="sd">        :type save_dir: str</span>
<span class="sd">        :param tag: Optional tag for the checkpoint</span>
<span class="sd">        :param max_num: Maximum number of checkpoints to keep, defaults to 3</span>
<span class="sd">        :type max_num: int</span>
<span class="sd">        :param max_mem: Maximum memory in MB for checkpoints, defaults to 1000</span>
<span class="sd">        :type max_mem: int</span>
<span class="sd">        :param client_state: Additional state to save, defaults to {}</span>
<span class="sd">        :type client_state: dict</span>
<span class="sd">        :param save_latest: Whether to save as latest checkpoint, defaults to True</span>
<span class="sd">        :type save_latest: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.load_ckpt"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.load_ckpt">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_ckpt</span><span class="p">(</span>  <span class="c1"># pylint: disable=R0917</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">load_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">tag</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">load_module_strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">load_optimizer_states</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">load_lr_scheduler_states</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">load_module_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load training checkpoint with various options.</span>

<span class="sd">        :param model: The model to load checkpoint into</span>
<span class="sd">        :param load_dir: Directory containing the checkpoint</span>
<span class="sd">        :type load_dir: str</span>
<span class="sd">        :param tag: Optional specific checkpoint tag to load</span>
<span class="sd">        :param load_module_strict: Whether to use strict loading for module states, defaults to True</span>
<span class="sd">        :type load_module_strict: bool</span>
<span class="sd">        :param load_optimizer_states: Whether to load optimizer states, defaults to True</span>
<span class="sd">        :type load_optimizer_states: bool</span>
<span class="sd">        :param load_lr_scheduler_states: Whether to load learning rate scheduler states, defaults to True</span>
<span class="sd">        :type load_lr_scheduler_states: bool</span>
<span class="sd">        :param load_module_only: Whether to load only the module states, defaults to False</span>
<span class="sd">        :type load_module_only: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.all_reduce"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.all_reduce">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                   <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
                   <span class="n">op</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform all-reduce operation across distributed processes.</span>

<span class="sd">        :param data: Data to be reduced, can be a tensor or dictionary of tensors</span>
<span class="sd">        :type data: Union[torch.Tensor, Dict[str, torch.Tensor]]</span>
<span class="sd">        :param op: Reduction operation (&#39;mean&#39;, &#39;max&#39;, &#39;sum&#39;)</span>
<span class="sd">        :type op: str</span>

<span class="sd">        :return: Reduced data in the same format as input</span>
<span class="sd">        :rtype: Union[torch.Tensor, Dict[str, torch.Tensor], float, int]</span>
<span class="sd">        :raises AssertionError: If op is not one of &#39;mean&#39;, &#39;max&#39;, &#39;sum&#39;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">op</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">ret</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">op</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">is_tensor</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">data</span><span class="p">])</span>
                <span class="n">is_tensor</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">is_cpu_tensor</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>

            <span class="k">if</span> <span class="n">is_cpu_tensor</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">())</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">MAX</span> <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span> <span class="k">else</span> <span class="n">dist</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_cpu_tensor</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">is_tensor</span> <span class="k">else</span> <span class="n">data</span></div>

<div class="viewcode-block" id="StrategyBase.all_gather"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.all_gather">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span>
                                                        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gather data from all distributed processes.</span>

<span class="sd">        :param data: Data to be gathered, can be a tensor or dictionary of tensors</span>
<span class="sd">        :type data: Union[torch.Tensor, dict]</span>

<span class="sd">        :return: Gathered data concatenated from all processes</span>
<span class="sd">        :rtype: Union[torch.Tensor, dict]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">ret</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">data</span><span class="p">])</span>
            <span class="n">is_cpu_tensor</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span>

            <span class="n">ret</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)]</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()))</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_cpu_tensor</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.print"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.print">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">print</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">msg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Print messages with timestamp, but only on rank 0.</span>

<span class="sd">        :param msg: Messages to print</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">current_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
        <span class="n">time_str</span> <span class="o">=</span> <span class="n">current_time</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[StrategyINFO </span><span class="si">{</span><span class="n">time_str</span><span class="si">}</span><span class="s2">] &quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">msg</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.is_rank_0"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.is_rank_0">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">is_rank_0</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if current process is rank 0.</span>

<span class="sd">        :return: True if current process is rank 0</span>
<span class="sd">        :rtype: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="StrategyBase.get_rank"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.get_rank">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">get_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get current process rank.</span>

<span class="sd">        :return: Current process rank</span>
<span class="sd">        :rtype: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.unwrap_model"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.unwrap_model">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">unwrap_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Unwrap model from strategy-specific wrappers.</span>

<span class="sd">        :param model: Model to unwrap</span>
<span class="sd">        :type model: nn.Module</span>

<span class="sd">        :return: Unwrapped model</span>
<span class="sd">        :rtype: nn.Module</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;module&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span>
        <span class="k">return</span> <span class="n">model</span></div>

<div class="viewcode-block" id="StrategyBase.prepare_models_and_optimizers"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.prepare_models_and_optimizers">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_models_and_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actor</span><span class="p">,</span> <span class="n">critic</span><span class="p">,</span> <span class="n">reward_models</span><span class="p">,</span> <span class="n">initial_model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare models, optimizers and schedulers for training.</span>

<span class="sd">        :param actor: Actor model</span>
<span class="sd">        :type actor: nn.Module</span>
<span class="sd">        :param critic: Critic model</span>
<span class="sd">        :type critic: nn.Module</span>
<span class="sd">        :param reward_models: Reward models</span>
<span class="sd">        :type reward_models: nn.Module</span>
<span class="sd">        :param initial_model: Initial model for reference</span>
<span class="sd">        :type initial_model: nn.Module</span>
<span class="sd">        :param args: Training arguments</span>
<span class="sd">        :type args: argparse.Namespace</span>
<span class="sd">        :param max_steps: Maximum training steps</span>
<span class="sd">        :type max_steps: int</span>

<span class="sd">        :return: Tuple of prepared models, optimizers, and schedulers</span>
<span class="sd">        :rtype: tuple</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="s2">&quot;is_actor&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="n">fsdp_enable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">fsdp</span>
        <span class="c1"># For FSDP: wrap model first, then create optimizer</span>
        <span class="k">if</span> <span class="n">fsdp_enable</span><span class="p">:</span>
            <span class="n">actor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">initial_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">initial_model</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">critic</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">critic</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">critic</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">remote_rm_url</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward_models</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                    <span class="n">reward_models</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shard_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">reward_models</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">reward_models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">reward_models</span><span class="p">,</span> <span class="n">shard_size</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

        <span class="c1"># Configure optimizers</span>
        <span class="n">actor_optim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">(</span>
            <span class="n">actor</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">adam_betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">l2</span>
        <span class="p">)</span>

        <span class="n">critic_optim</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic_pretrain</span><span class="p">:</span>
            <span class="n">critic_optim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">(</span>
                <span class="n">critic</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic_learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">adam_betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">l2</span>
            <span class="p">)</span>

        <span class="c1"># Configure schedulers</span>
        <span class="n">actor_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
            <span class="s2">&quot;cosine_with_min_lr&quot;</span><span class="p">,</span>
            <span class="n">actor_optim</span><span class="p">,</span>
            <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">lr_warmup_ratio</span><span class="p">),</span>
            <span class="n">num_training_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="n">scheduler_specific_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;min_lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">actor_learning_rate</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">},</span>
        <span class="p">)</span>

        <span class="n">critic_scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic_pretrain</span><span class="p">:</span>
            <span class="n">critic_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
                <span class="s2">&quot;cosine_with_min_lr&quot;</span><span class="p">,</span>
                <span class="n">critic_optim</span><span class="p">,</span>
                <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">lr_warmup_ratio</span><span class="p">),</span>
                <span class="n">num_training_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
                <span class="n">scheduler_specific_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;min_lr&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">critic_learning_rate</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">},</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_and_clear_cache</span><span class="p">()</span>
        <span class="c1"># Prepare with strategy if not using FSDP</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fsdp_enable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
                <span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">actor_optim</span><span class="p">,</span> <span class="n">actor_scheduler</span><span class="p">),</span>
                <span class="p">(</span><span class="n">critic</span><span class="p">,</span> <span class="n">critic_optim</span><span class="p">,</span> <span class="n">critic_scheduler</span><span class="p">),</span>
                <span class="n">reward_models</span><span class="p">,</span>
                <span class="n">initial_model</span><span class="p">,</span>
                <span class="n">is_rlhf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="n">actor_optim</span><span class="p">,</span> <span class="n">actor_scheduler</span><span class="p">),</span>
                <span class="p">(</span><span class="n">critic</span><span class="p">,</span> <span class="n">critic_optim</span><span class="p">,</span> <span class="n">critic_scheduler</span><span class="p">),</span>
                <span class="n">reward_models</span><span class="p">,</span>
                <span class="n">initial_model</span><span class="p">,</span>
            <span class="p">)</span></div>

    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_reward_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reward_model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e8</span><span class="p">),</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare optimizers and schedulers for reward model training.</span>

<span class="sd">        :param reward_models: Reward models</span>
<span class="sd">        :type reward_models: nn.Module</span>
<span class="sd">        :param args: Training arguments</span>
<span class="sd">        :type args: argparse.Namespace</span>
<span class="sd">        :param max_steps: Maximum training steps</span>
<span class="sd">        :type max_steps: int</span>

<span class="sd">        :return: Tuple of prepared model, optimizer, and scheduler</span>
<span class="sd">        :rtype: tuple</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fsdp_enable</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">fsdp</span>
        <span class="c1"># For FSDP: wrap model first, then create optimizer</span>
        <span class="k">if</span> <span class="n">fsdp_enable</span><span class="p">:</span>
            <span class="n">reward_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_model</span><span class="p">(</span><span class="n">reward_model</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Configure optimizers</span>
        <span class="n">reward_model_optim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">(</span>
            <span class="n">reward_model</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">actor_learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">adam_betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">l2</span>
        <span class="p">)</span>

        <span class="c1"># Configure schedulers</span>
        <span class="n">reward_model_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
            <span class="s2">&quot;cosine_with_min_lr&quot;</span><span class="p">,</span>
            <span class="n">reward_model_optim</span><span class="p">,</span>
            <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">max_steps</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_ratio</span><span class="p">),</span>
            <span class="n">num_training_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="n">scheduler_specific_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;min_lr&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">actor_learning_rate</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">},</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sync_and_clear_cache</span><span class="p">()</span>
        <span class="c1"># Prepare with strategy if not using FSDP</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">fsdp_enable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
                <span class="p">(</span><span class="n">reward_model</span><span class="p">,</span> <span class="n">reward_model_optim</span><span class="p">,</span> <span class="n">reward_model_scheduler</span><span class="p">),</span>
                <span class="n">is_rlhf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For FSDP: return wrapped model and optimizers</span>
            <span class="k">return</span> <span class="n">reward_model</span><span class="p">,</span> <span class="n">reward_model_optim</span><span class="p">,</span> <span class="n">reward_model_scheduler</span>

<div class="viewcode-block" id="StrategyBase.report_memory"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.report_memory">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">report_memory</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Report GPU memory usage statistics.</span>

<span class="sd">        :param prefix: Prefix string for the memory report</span>
<span class="sd">        :type prefix: str</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">usable</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()</span>
        <span class="n">used</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="n">total</span> <span class="o">-</span> <span class="n">usable</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;MEMORY STATUS: </span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">, DRIVER_USED=</span><span class="si">{</span><span class="n">used</span><span class="si">}</span><span class="s2"> GB, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;ALLOCATED=</span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.setup_inference_engine"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.setup_inference_engine">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">setup_inference_engine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">engine_type</span><span class="o">=</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="n">actor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize and setup the inference engine.</span>

<span class="sd">        :param args: Configuration arguments</span>
<span class="sd">        :type args: argparse.Namespace</span>
<span class="sd">        :param engine_type: Type of inference engine (&#39;vllm&#39; or &#39;sglang&#39;)</span>
<span class="sd">        :type engine_type: str</span>
<span class="sd">        :param actor: The actor module, if passed, will be used to update engine weights</span>
<span class="sd">        :type actor: torch.nn.Module</span>

<span class="sd">        :return: Initialized inference engine</span>
<span class="sd">        :rtype: object</span>
<span class="sd">        :raises ValueError: If engine_type is not supported</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="o">=</span> <span class="n">engine_type</span>

        <span class="k">if</span> <span class="n">engine_type</span> <span class="o">==</span> <span class="s2">&quot;vllm&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">=</span> <span class="n">get_vllm_engine_for_rollout</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">=</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">WAKEUP</span>
        <span class="k">elif</span> <span class="n">engine_type</span> <span class="o">==</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="o">=</span> <span class="n">get_sglang_engine_for_rollout</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">=</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">WAKEUP</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="n">engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">actor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_engine_weights</span><span class="p">(</span><span class="n">actor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maybe_sleep_inference_engine</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span></div>

<div class="viewcode-block" id="StrategyBase.maybe_sleep_inference_engine"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.maybe_sleep_inference_engine">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">maybe_sleep_inference_engine</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Put the inference engine to sleep if enabled and available.</span>

<span class="sd">        Sleeps the engine to conserve memory when not in use. Only supports vLLM and SGLang engines.</span>
<span class="sd">        After sleeping, synchronizes and clears the cache.</span>

<span class="sd">        :raises ValueError: If the inference engine type is not supported</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">enable_engine_sleep</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">sleep</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">=</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">SLEEPED</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">sync_and_clear_cache</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;Sleeped inference engine&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.wakeup_inference_engine"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.wakeup_inference_engine">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">wakeup_inference_engine</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wake up the inference engine from sleep state.</span>

<span class="sd">        To avoid OOM, we:</span>
<span class="sd">            1. sync and clear cache</span>
<span class="sd">            2. wakeup engine</span>

<span class="sd">        :raises ValueError: If the inference engine type is not supported</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">==</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">WAKEUP</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_and_clear_cache</span><span class="p">()</span>
        <span class="n">wkup_t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">wake_up</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># torch.cuda.reset_max_memory_allocated()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">report_memory</span><span class="p">(</span><span class="s2">&quot;after ppo training, after wakeup inference engine&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span><span class="si">}</span><span class="s2"> wakeup, TIMECOST </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">wkup_t0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_status</span> <span class="o">=</span> <span class="n">EngineStatus</span><span class="o">.</span><span class="n">WAKEUP</span></div>

<div class="viewcode-block" id="StrategyBase.engine_generate_local"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.engine_generate_local">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">engine_generate_local</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">prompt_token_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">multi_modal_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">EasyDict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform text or multimodal generation using different inference engines based on the input mode.</span>

<span class="sd">        :param sampling_params: Parameters used for controlling the generation process (e.g., temperature, top_k).</span>
<span class="sd">        :param prompt_token_ids: List of text token IDs.</span>
<span class="sd">        :param multi_modal_inputs: A list of dictionaries representing multimodal inputs.</span>
<span class="sd">                                   Each dictionary should contain a raw text under the &quot;prompt&quot; key,</span>
<span class="sd">                                   and additional modalities (such as images) under the &quot;multi_modal_data&quot; key.</span>
<span class="sd">                                   Example:</span>
<span class="sd">                                   multi_modal_inputs = [{</span>
<span class="sd">                                       &quot;prompt&quot;: [...],</span>
<span class="sd">                                       &quot;multi_modal_data&quot;: {</span>
<span class="sd">                                           &quot;image&quot;: [...],</span>
<span class="sd">                                           &quot;video&quot;: [...]</span>
<span class="sd">                                       }</span>
<span class="sd">                                   }]</span>
<span class="sd">        :return: A list of generated outputs in EasyDict format, produced by the selected inference engine.</span>
<span class="sd">        :raises ValueError: If both prompt_token_ids and multi_modal_inputs are None.</span>
<span class="sd">        :raises ValueError: If both prompt_token_ids and multi_modal_inputs are not None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">prompt_token_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">multi_modal_inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either prompt_token_ids or multi_modal_inputs must be provided.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt_token_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">multi_modal_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Both prompt_token_ids and multi_modal_inputs can not be provided at the same time.&quot;</span><span class="p">)</span>

        <span class="c1"># if inference engine is vllm</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="o">==</span> <span class="s2">&quot;vllm&quot;</span><span class="p">:</span>
            <span class="c1"># For vLLM:</span>
            <span class="c1"># - If `prompt_token_ids` is provided, it indicates a pure LLM (text-only) generation.</span>
            <span class="c1"># - If `prompts` (i.e., `multi_modal_inputs`) is provided, it indicates a VLM (multimodal) generation.</span>
            <span class="k">if</span> <span class="n">multi_modal_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">multi_modal_inputs</span>
            <span class="k">elif</span> <span class="n">prompt_token_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt_token_ids</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either prompt (multi_modal_inputs) or prompt_token_ids must be provided.&quot;</span><span class="p">)</span>

            <span class="n">vllm_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
                <span class="n">prompts</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">EasyDict</span><span class="p">(</span>
                    <span class="n">prompt_token_ids</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">,</span>
                    <span class="n">output_token_ids</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">token_ids</span><span class="p">,</span>
                <span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">vllm_outputs</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="o">==</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>

            <span class="k">if</span> <span class="n">multi_modal_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># VLM case</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2"> VLM branch&quot;</span><span class="p">)</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">multi_modal_inputs</span><span class="p">]</span>

                <span class="c1"># Handle cases where some prompts might not have images</span>
                <span class="c1"># Flatten nested list format if needed: [[PIL.Image]] -&gt; [PIL.Image]</span>
                <span class="n">image</span> <span class="o">=</span> <span class="p">[(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">img</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;multi_modal_data&quot;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">multi_modal_inputs</span><span class="p">)]</span>

                <span class="n">sglang_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                    <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
                    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>  <span class="c1"># skip_tokenizer_init must be False</span>
                    <span class="n">image_data</span><span class="o">=</span><span class="n">image</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="c1"># VLM case: prompt_token_ids should be provided separately or extracted from sglang output</span>
                <span class="c1"># Since sglang doesn&#39;t return prompt_token_ids in VLM mode, we set it to None here</span>
                <span class="c1"># and expect the caller to fill it in if needed</span>
                <span class="k">return</span> <span class="p">[</span>
                    <span class="n">EasyDict</span><span class="p">(</span>
                        <span class="n">prompt_token_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Will be filled by caller if needed</span>
                        <span class="n">output_token_ids</span><span class="o">=</span><span class="n">sglang_outputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;output_ids&quot;</span><span class="p">],</span>
                    <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sglang_outputs</span><span class="p">))</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># text-only case</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank </span><span class="si">{</span><span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span><span class="si">}</span><span class="s2"> text-only branch&quot;</span><span class="p">)</span>
                <span class="n">sglang_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                    <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
                    <span class="n">input_ids</span><span class="o">=</span><span class="n">prompt_token_ids</span><span class="p">,</span>
                    <span class="n">image_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># Text-only case: prompt_token_ids is available from input</span>
                <span class="k">return</span> <span class="p">[</span>
                    <span class="n">EasyDict</span><span class="p">(</span>
                        <span class="n">prompt_token_ids</span><span class="o">=</span><span class="n">prompt_token_ids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                        <span class="n">output_token_ids</span><span class="o">=</span><span class="n">sglang_outputs</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;output_ids&quot;</span><span class="p">],</span>
                    <span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sglang_outputs</span><span class="p">))</span>
                <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase._build_multimodal_inputs"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase._build_multimodal_inputs">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_multimodal_inputs</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">all_prompts</span><span class="p">,</span> <span class="n">all_images</span><span class="p">,</span> <span class="n">images_num</span><span class="p">,</span> <span class="n">all_videos</span><span class="p">,</span> <span class="n">videos_num</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build multimodal inputs for inference engine (vLLM/SGLang).</span>

<span class="sd">        This function supports two input formats for images and videos to accommodate</span>
<span class="sd">        different data preprocessing approaches:</span>

<span class="sd">        Format 1 - Nested List (multi-image/video per prompt already grouped):</span>
<span class="sd">            all_images = [[img1_a, img1_b], [img2_a], [img3_a, img3_b, img3_c]]</span>
<span class="sd">            images_num = [2, 1, 3]</span>
<span class="sd">            -&gt; all_images[i] is directly used as the image list for prompt i</span>

<span class="sd">        Format 2 - Flattened List (all images/videos in a single flat list):</span>
<span class="sd">            all_images = [img1_a, img1_b, img2_a, img3_a, img3_b, img3_c]</span>
<span class="sd">            images_num = [2, 1, 3]</span>
<span class="sd">            -&gt; images are sliced based on images_num: [0:2], [2:3], [3:6]</span>

<span class="sd">        :param all_prompts: List of text prompts</span>
<span class="sd">        :param all_images: Images in nested or flattened format, or None</span>
<span class="sd">        :param images_num: Number of images per prompt</span>
<span class="sd">        :param all_videos: Videos in nested or flattened format, or None</span>
<span class="sd">        :param videos_num: Number of videos per prompt</span>
<span class="sd">        :return: List of dicts with &#39;prompt&#39; and optional &#39;multi_modal_data&#39; keys</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">img_start_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">vid_start_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_prompts</span><span class="p">):</span>
            <span class="n">img_num</span> <span class="o">=</span> <span class="n">images_num</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="n">vid_num</span> <span class="o">=</span> <span class="n">videos_num</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>

            <span class="c1"># Support two input formats:</span>
            <span class="c1"># 1. Nested list: all_images[i] is already a list of images for this prompt</span>
            <span class="c1"># 2. Flattened list: all_images is a flat list, slice by img_num</span>
            <span class="k">if</span> <span class="n">all_images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">all_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="n">img_num</span><span class="p">:</span>
                    <span class="n">img_list</span> <span class="o">=</span> <span class="n">all_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">img_list</span> <span class="o">=</span> <span class="n">all_images</span><span class="p">[</span><span class="n">img_start_idx</span><span class="p">:</span><span class="n">img_start_idx</span> <span class="o">+</span> <span class="n">img_num</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">img_list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Same logic for videos</span>
            <span class="k">if</span> <span class="n">all_videos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_videos</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">all_videos</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_videos</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="n">vid_num</span><span class="p">:</span>
                    <span class="n">vid_list</span> <span class="o">=</span> <span class="n">all_videos</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">vid_list</span> <span class="o">=</span> <span class="n">all_videos</span><span class="p">[</span><span class="n">vid_start_idx</span><span class="p">:</span><span class="n">vid_start_idx</span> <span class="o">+</span> <span class="n">vid_num</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vid_list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">multi_modal_data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">img_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">img_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">multi_modal_data</span><span class="p">[</span><span class="s2">&quot;image&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">img_list</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">vid_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">vid_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">multi_modal_data</span><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vid_list</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_modal_data</span><span class="p">:</span>
                <span class="c1"># remove the vision start and end tokens for data after apply chat template.</span>
                <span class="c1"># Use regex to handle multiple &lt;|image_pad|&gt; tokens (e.g., for high-res images)</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&lt;\|vision_start\|&gt;(&lt;\|image_pad\|&gt;)+&lt;\|vision_end\|&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;&lt;\|vision_start\|&gt;(&lt;\|video_pad\|&gt;)+&lt;\|vision_end\|&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">prompt</span><span class="p">)</span>
                <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                <span class="p">})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                    <span class="s2">&quot;multi_modal_data&quot;</span><span class="p">:</span> <span class="n">multi_modal_data</span><span class="p">,</span>
                <span class="p">})</span>
            <span class="n">img_start_idx</span> <span class="o">+=</span> <span class="n">img_num</span>
            <span class="n">vid_start_idx</span> <span class="o">+=</span> <span class="n">vid_num</span>
        <span class="k">return</span> <span class="n">inputs</span></div>

<div class="viewcode-block" id="StrategyBase.gather_and_generate"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.gather_and_generate">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">gather_and_generate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sampling_params</span><span class="p">,</span>
        <span class="n">all_prompt_token_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">all_prompts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">all_images</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sleep_engine</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">images_num</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">all_videos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">videos_num</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gather prompts across distributed ranks and perform text/multimodal generation.</span>

<span class="sd">        This method coordinates distributed generation by:</span>
<span class="sd">        1. Gathering prompts from all ranks within a vLLM tensor parallel group</span>
<span class="sd">        2. Performing batched generation using the inference engine</span>
<span class="sd">        3. Splitting generated outputs and returning each rank&#39;s portion</span>
<span class="sd">        4. Optionally putting the inference engine to sleep to conserve memory</span>

<span class="sd">        For multimodal inputs, supports flexible input formats:</span>
<span class="sd">        - One prompt with one image</span>
<span class="sd">        - One prompt with multiple images</span>
<span class="sd">        - One prompt with video(s) only (no images)</span>
<span class="sd">        - One prompt with one or more videos</span>
<span class="sd">        - Mixed image and video inputs</span>

<span class="sd">        :param sampling_params: Parameters controlling generation (e.g., temperature, top_k, max_tokens)</span>
<span class="sd">        :type sampling_params: Any</span>
<span class="sd">        :param all_prompt_token_ids: Token IDs for text-only prompts, defaults to None</span>
<span class="sd">        :type all_prompt_token_ids: Optional[List[List[int]]]</span>
<span class="sd">        :param all_prompts: Raw text prompts for multimodal generation, defaults to None</span>
<span class="sd">        :type all_prompts: Optional[List[str]]</span>
<span class="sd">        :param all_images: Images corresponding to prompts for VLM generation, defaults to None</span>
<span class="sd">        :type all_images: Optional[List]</span>
<span class="sd">        :param sleep_engine: Whether to sleep the inference engine after generation, defaults to True</span>
<span class="sd">        :type sleep_engine: bool</span>
<span class="sd">        :param images_num: Number of images per prompt (for multi-image scenarios), defaults to None</span>
<span class="sd">        :type images_num: Optional[List[int]]</span>
<span class="sd">        :param all_videos: Videos corresponding to prompts for video generation, defaults to None</span>
<span class="sd">        :type all_videos: Optional[List]</span>
<span class="sd">        :param videos_num: Number of videos per prompt, defaults to None</span>
<span class="sd">        :type videos_num: Optional[List[int]]</span>

<span class="sd">        :return: List of generation outputs for the current rank, each containing prompt_token_ids and output_token_ids</span>
<span class="sd">        :rtype: List[EasyDict]</span>
<span class="sd">        :raises NotImplementedError: If inference engine is not initialized</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Inference engine is not initialized.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wakeup_inference_engine</span><span class="p">()</span>

        <span class="c1"># is_multimodal = all_images is not None</span>
        <span class="c1"># NOTE: not only check if all_images is None, but also check if it contains non-None elements</span>
        <span class="c1"># If all_images is [None, None, ...], any(img is not None for img in all_images) will return False</span>
        <span class="c1"># Same logic applies to all_videos</span>
        <span class="n">is_multimodal</span> <span class="o">=</span> <span class="p">(((</span><span class="n">all_images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">img</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">all_images</span><span class="p">))</span>
                         <span class="ow">or</span> <span class="p">((</span><span class="n">all_videos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="n">vid</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">vid</span> <span class="ow">in</span> <span class="n">all_videos</span><span class="p">)))</span>

        <span class="k">if</span> <span class="n">is_multimodal</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_multimodal_inputs</span><span class="p">(</span>
                <span class="n">all_prompts</span><span class="o">=</span><span class="n">all_prompts</span><span class="p">,</span>
                <span class="n">all_images</span><span class="o">=</span><span class="n">all_images</span><span class="p">,</span>
                <span class="n">images_num</span><span class="o">=</span><span class="n">images_num</span><span class="p">,</span>
                <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos</span><span class="p">,</span>
                <span class="n">videos_num</span><span class="o">=</span><span class="n">videos_num</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">all_prompt_token_ids</span>
            <span class="k">assert</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="n">gather_inputs_object_for_inference</span><span class="p">(</span><span class="n">input_data</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">engine_mp_group</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Start VLM gather_and_generate ..., total prompts: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">all_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">engine_generate_local</span><span class="p">(</span>
            <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
            <span class="n">prompt_token_ids</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="n">inputs</span><span class="p">,</span>
            <span class="n">multi_modal_inputs</span><span class="o">=</span><span class="n">inputs</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">engine_mp_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine_mp_group</span><span class="p">)</span>
        <span class="n">num_prompts_per_rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span> <span class="o">//</span> <span class="n">engine_mp_size</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span> <span class="o">%</span> <span class="n">engine_mp_size</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">cur_rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">engine_mp_group</span><span class="p">)</span>
        <span class="n">local_outputs</span> <span class="o">=</span> <span class="n">all_outputs</span><span class="p">[</span><span class="n">cur_rank</span> <span class="o">*</span> <span class="n">num_prompts_per_rank</span><span class="p">:(</span><span class="n">cur_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_prompts_per_rank</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="o">==</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>
            <span class="c1"># For SGLang VLM case, prompt_token_ids is set to None in engine_generate_local</span>
            <span class="c1"># We need to fill it with the actual token_ids here</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">local_outputs</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span> <span class="o">=</span> <span class="n">all_prompt_token_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">sleep_engine</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maybe_sleep_inference_engine</span><span class="p">()</span>

        <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">genlen_analyser</span><span class="o">.</span><span class="n">collect</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profile_step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_rank_0</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;step </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_profile_step</span><span class="si">}</span><span class="s2"> generate length: &quot;</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_profile_step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Finished gather_and_generate, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">local_outputs</span><span class="p">)</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">local_outputs</span></div>

<div class="viewcode-block" id="StrategyBase.update_engine_weights"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.update_engine_weights">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">update_engine_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the weights of the inference engine from the actor model.</span>

<span class="sd">        :param actor: The actor model whose weights will be copied</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;Skip update engine weights since inference engine is not initialized.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="c1"># 1. wakeup engine if sleeped</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wakeup_inference_engine</span><span class="p">()</span>

        <span class="c1"># TODO: unify the broadcast manager</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;vllm&quot;</span><span class="p">,</span> <span class="s2">&quot;sglang&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">inference_engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_manager</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_manager</span> <span class="o">=</span> <span class="n">BroadcastManager</span><span class="p">(</span><span class="n">actor</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_engine</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_manager</span><span class="o">.</span><span class="n">broadcast_to_engine</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;finished update_engine_weights&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_and_clear_cache</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.sync_and_clear_cache"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.sync_and_clear_cache">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">sync_and_clear_cache</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Synchronize CUDA operations and clear the cache.</span>

<span class="sd">        Performs three operations:</span>
<span class="sd">        1. CUDA synchronization</span>
<span class="sd">        2. Distributed barrier</span>
<span class="sd">        3. CUDA cache clearing</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span></div>

<div class="viewcode-block" id="StrategyBase.init_model_context"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.init_model_context">[docs]</a>    <span class="nd">@contextmanager</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">init_model_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Context manager for model initialization.</span>

<span class="sd">        Currently does nothing by default, used only for DeepSpeed.</span>
<span class="sd">        Reports memory usage after completion.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Do nothing by default, only deepspeed</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">report_memory</span><span class="p">(</span><span class="s2">&quot;Finished init_model_context&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.maybe_offload_optimizer"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.maybe_offload_optimizer">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">maybe_offload_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>  <span class="c1"># pylint: disable=W0613</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Placeholder for FSDP optimizer offloading functionality.</span>
<span class="sd">        :param optimizer: The optimizer to potentially offload</span>
<span class="sd">        :type optimizer: torch.optim.Optimizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;maybe_offload_optimizer not implemented and Skipped&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="StrategyBase.maybe_load_optimizer"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.StrategyBase.maybe_load_optimizer">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="nf">maybe_load_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()):</span>  <span class="c1"># pylint: disable=W0613</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Placeholder for FSDP optimizer loading functionality.</span>
<span class="sd">        :param optimizer: The optimizer to potentially load</span>
<span class="sd">        :type optimizer: torch.optim.Optimizer</span>
<span class="sd">        :param device: Target device for loading</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;maybe_load_optimizer not implemented and Skipped&quot;</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="is_actor"><a class="viewcode-back" href="../../../api_doc/strategy/strategy_base.html#lightrft.strategy.strategy_base.is_actor">[docs]</a><span class="k">def</span><span class="w"> </span><span class="nf">is_actor</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if a model is an actor model.</span>

<span class="sd">    :param model: The model to check</span>
<span class="sd">    :return: True if the model is an actor, False otherwise</span>
<span class="sd">    :rtype: bool</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;is_actor&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>
</pre></div>

              </article>
              
            </div>
            <footer>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2025, OpenDILab.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../../"
    src="../../../_static/documentation_options.js"></script>
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
  <script src="../../../_static/doctools.js"></script>
  <script src="../../../_static/sphinx_highlight.js"></script>
  <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  <script src="../../../_static/js/language_switch.js"></script>
  

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/LightRFT" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>