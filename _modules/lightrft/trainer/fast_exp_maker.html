


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lightrft.trainer.fast_exp_maker &mdash; LightRFT v0.1.1 documentation</title>
  

  <link rel="shortcut icon" href="../../../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/readthedocs.css" type="text/css" />
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  <script type="text/javascript">
    var collapsedSections = [];
  </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/LightRFT" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/LightZero" target="_blank">
                  <span class="dropdown-title">LightZero </span>
                  <p>OpenDILab Decision Monte Carlo Tree Search Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GenerativeRL" target="_blank">
                  <span class="dropdown-title">GenerativeRL </span>
                  <p>OpenDILab Generative AI Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start/index.html">Quick Start</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide &amp; Best Practices</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../best_practice/index.html">Best Practices</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/utils/index.html">lightrft.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/datasets/index.html">lightrft.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/models/index.html">lightrft.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/strategy/index.html">lightrft.strategy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_doc/trainer/index.html">lightrft.trainer</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>lightrft.trainer.fast_exp_maker</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <h1>Source code for lightrft.trainer.fast_exp_maker</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">FastExperienceMaker Module</span>

<span class="sd">This module provides an optimized experience maker for RLHF (Reinforcement Learning from Human Feedback)</span>
<span class="sd">that supports high-performance inference backends like VLLM and SGLang. It extends the base</span>
<span class="sd">NaiveExperienceMaker with enhanced features for multimodal data processing, reward computation,</span>
<span class="sd">and advantage estimation.</span>

<span class="sd">Key Features:</span>
<span class="sd">    - VLLM/SGLang backend support for efficient text generation</span>
<span class="sd">    - Multimodal (vision-language) data processing</span>
<span class="sd">    - Multiple advantage estimation methods (GAE, RLOO, REINFORCE, Group Norm)</span>
<span class="sd">    - Flexible reward model composition with custom reward functions</span>
<span class="sd">    - Sample packing support for improved training efficiency</span>
<span class="sd">    - Running reward normalization and advantage whitening</span>

<span class="sd">Classes:</span>
<span class="sd">    MultimodalDataProcessor: Handles preprocessing of mixed text/image data</span>
<span class="sd">    RewardComputationEngine: Manages reward model inference and aggregation</span>
<span class="sd">    FastExperienceMaker: Main experience generation class</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pathlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">easydict</span><span class="w"> </span><span class="kn">import</span> <span class="n">EasyDict</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SamplingParams</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.models.utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_approx_kl</span><span class="p">,</span>
    <span class="n">compute_reward</span><span class="p">,</span>
    <span class="n">masked_mean</span><span class="p">,</span>
    <span class="n">unpacking_samples</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.models.actor_modality</span><span class="w"> </span><span class="kn">import</span> <span class="n">ActorModality</span><span class="p">,</span> <span class="n">get_supported_parameters</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.trainer.experience_maker</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Experience</span><span class="p">,</span>
    <span class="n">NaiveExperienceMaker</span><span class="p">,</span>
    <span class="n">Samples</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.trainer.experience_maker_vl</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExperienceVL</span><span class="p">,</span>
    <span class="n">SamplesVL</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.utils.remote_rm_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">remote_rm_fn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">lightrft.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">Timer</span><span class="p">,</span> <span class="n">get_current_device</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunningMoments</span><span class="p">,</span> <span class="n">compute_clip_fraction</span><span class="p">,</span> <span class="n">get_cpgd_advantages_returns</span><span class="p">,</span> <span class="n">fire_sampling</span><span class="p">,</span> <span class="n">vllm_ge_0130</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.advantage_calculator</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_advantage_calculator</span><span class="p">,</span> <span class="n">normalize_advantages_cross_batch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.image_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">normalize_images</span><span class="p">,</span> <span class="n">get_images_num</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.video_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">normalize_videos</span><span class="p">,</span> <span class="n">get_videos_num</span>

<span class="c1"># ============================================================================</span>
<span class="c1"># Data Structures</span>
<span class="c1"># ============================================================================</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">_SamplesOutput</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Lightweight dataclass for caching intermediate computation results during experience creation.</span>

<span class="sd">    This structure serves as a unified container for all data flowing through the parallel</span>
<span class="sd">    experience generation pipeline, including sequences, attention masks, multimodal inputs,</span>
<span class="sd">    and model outputs (log probabilities, values, rewards).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        sequences: Token ID sequences [batch_size, seq_len]</span>
<span class="sd">        attention_mask: Attention mask for sequences</span>
<span class="sd">        action_mask: Mask indicating which tokens are part of the generated response</span>
<span class="sd">        num_actions: Number of action tokens per sequence</span>
<span class="sd">        packed_seq_lens: Sequence lengths for packed samples (if packing enabled)</span>
<span class="sd">        response_length: Length of generated responses</span>
<span class="sd">        total_length: Total sequence length (prompt + response)</span>
<span class="sd">        prompts: Original text prompts</span>
<span class="sd">        labels: Optional labels for the samples</span>

<span class="sd">        # Vision-Language Model (VLM) specific fields</span>
<span class="sd">        pixel_values: Processed pixel values for images (Qwen-VL format)</span>
<span class="sd">        pixel_values_videos: Processed pixel values for videos (Qwen-VL format)</span>
<span class="sd">        image_grid_thw: Image grid dimensions [temporal, height, width]</span>
<span class="sd">        video_grid_thw: Video grid dimensions [temporal, height, width]</span>
<span class="sd">        raw_images: Original PIL images</span>
<span class="sd">        references: Reference texts for evaluation</span>
<span class="sd">        image_num: Number of images per sample</span>

<span class="sd">        # Model inference outputs</span>
<span class="sd">        action_log_probs: Log probabilities from actor model</span>
<span class="sd">        base_action_log_probs: Log probabilities from initial/reference model</span>
<span class="sd">        value: Value estimates from critic model</span>
<span class="sd">        rewards: Reward scores from reward model(s)</span>
<span class="sd">        kl: KL divergence between actor and reference policy</span>
<span class="sd">        inputs_extra_kwargs: Additional model-specific inputs</span>
<span class="sd">        prompt_and_output: Concatenated prompt+output text for reward models</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Core sequence data</span>
    <span class="n">sequences</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">action_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">num_actions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">packed_seq_lens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>
    <span class="n">response_length</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">total_length</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span>

    <span class="c1"># Vision-Language Model fields</span>
    <span class="n">pixel_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">image_grid_thw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">pixel_values_videos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">video_grid_thw</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">raw_images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">image_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">video_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Model outputs</span>
    <span class="n">action_log_probs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">base_action_log_probs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">rewards</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">reward_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Detailed reward metrics</span>
    <span class="n">kl</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">action_entropy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Entropy for high-entropy token filtering</span>
    <span class="n">inputs_extra_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">prompt_and_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># ============================================================================</span>
<span class="c1"># Helper Classes</span>
<span class="c1"># ============================================================================</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MultimodalDataProcessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Handles preprocessing of mixed text-only and image-text multimodal data.</span>

<span class="sd">    This processor separates text-only and multimodal samples, processes them through</span>
<span class="sd">    appropriate pipelines (tokenizer vs. multimodal processor), then merges results</span>
<span class="sd">    back in original order to maintain batch consistency.</span>

<span class="sd">    Key responsibilities:</span>
<span class="sd">        - Normalize image inputs (file paths, PIL images, bytes)</span>
<span class="sd">        - Separate text-only and image-text samples</span>
<span class="sd">        - Process each modality through appropriate pipeline</span>
<span class="sd">        - Expand samples by n_samples_per_prompt factor</span>
<span class="sd">        - Reconstruct original batch ordering</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer: Tokenizer for text-only samples</span>
<span class="sd">        processor: Multimodal processor for image-text samples</span>
<span class="sd">        prompt_max_len: Maximum prompt length for truncation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">prompt_max_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the multimodal data processor.</span>

<span class="sd">        :param tokenizer: HuggingFace tokenizer for text processing</span>
<span class="sd">        :type tokenizer: transformers.PreTrainedTokenizer</span>
<span class="sd">        :param processor: Multimodal processor (e.g., Qwen-VL processor)</span>
<span class="sd">        :type processor: Union[transformers.ProcessorMixin, Any]</span>
<span class="sd">        :param prompt_max_len: Maximum allowed prompt length</span>
<span class="sd">        :type prompt_max_len: int</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_max_len</span> <span class="o">=</span> <span class="n">prompt_max_len</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">process_multimodal_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">all_prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">all_images</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">all_references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">images_num</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">n_samples_per_prompt</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">all_videos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
        <span class="n">videos_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EasyDict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process multimodal batch - following original implementation exactly.</span>

<span class="sd">        This method is a direct port of the original process_multimodal_data to ensure</span>
<span class="sd">        functional equivalence.</span>

<span class="sd">        :param all_prompts: List of text prompts</span>
<span class="sd">        :type all_prompts: List[str]</span>
<span class="sd">        :param all_images: List of images (PIL.Image or None)</span>
<span class="sd">        :type all_images: List[Union[List[PIL.Image.Image], None]]</span>
<span class="sd">        :param all_references: Optional reference texts</span>
<span class="sd">        :type all_references: Optional[List[str]]</span>
<span class="sd">        :param images_num: Number of images per sample</span>
<span class="sd">        :type images_num: List[int]</span>
<span class="sd">        :param n_samples_per_prompt: Number of samples to generate per prompt</span>
<span class="sd">        :type n_samples_per_prompt: int</span>
<span class="sd">        :param all_videos: List of videos (List[str] or None)</span>
<span class="sd">        :type all_videos: Optional[List[Union[List[str], None]]]</span>
<span class="sd">        :param videos_num: Number of videos per sample</span>
<span class="sd">        :type videos_num: Optional[List[int]]</span>
<span class="sd">        :return: Dictionary containing processed data</span>
<span class="sd">        :rtype: EasyDict</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">n_samples_per_prompt</span>
        <span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_prompts</span><span class="p">)</span>

        <span class="c1"># Ensure all_images and all_videos are iterable even if None</span>
        <span class="k">if</span> <span class="n">all_images</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_images</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">L</span>
        <span class="k">if</span> <span class="n">all_videos</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_videos</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">L</span>

        <span class="c1"># ===== Stage 1: Separation =====</span>
        <span class="n">all_prompts_text</span><span class="p">,</span> <span class="n">all_prompts_multimodal</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">all_images_valid</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_videos_valid</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">text_idx</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">video</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">all_prompts</span><span class="p">,</span> <span class="n">all_images</span><span class="p">,</span> <span class="n">all_videos</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">image</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">video</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">all_prompts_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
                <span class="n">text_idx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">all_prompts_multimodal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
                <span class="n">all_images_valid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
                <span class="n">all_videos_valid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>

        <span class="c1"># ===== Stage 2: Expansion =====</span>
        <span class="n">all_prompts_text</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_prompts_text</span><span class="p">],</span> <span class="p">[])</span>
        <span class="n">all_prompts_multimodal</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">p</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_prompts_multimodal</span><span class="p">],</span> <span class="p">[])</span>
        <span class="n">all_images_valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">all_images_valid</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
        <span class="n">all_videos_valid</span> <span class="o">=</span> <span class="p">[</span><span class="n">vid</span> <span class="k">for</span> <span class="n">vid</span> <span class="ow">in</span> <span class="n">all_videos_valid</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
        <span class="n">all_images_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">num</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">images_num</span><span class="p">],</span> <span class="p">[])</span> <span class="k">if</span> <span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>
        <span class="n">all_videos_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">num</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">videos_num</span><span class="p">],</span> <span class="p">[])</span> <span class="k">if</span> <span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">L</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>

        <span class="c1"># ===== Stage 3-A: Text-only processing =====</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_prompts_text</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">inputs_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">all_prompts_text</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_max_len</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">all_prompt_token_ids_text</span> <span class="o">=</span> <span class="n">inputs_text</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_prompt_token_ids_text</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Initialize multimodal variables for text-only compatibility</span>
        <span class="n">all_prompt_token_ids_multimodal</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_images_pixel_values_multimodal</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_videos_pixel_values_multimodal</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_images_grid_thw_multimodal</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_videos_grid_thw_multimodal</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># ===== Stage 3-B: Multimodal processing =====</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_prompts_multimodal</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Processor required for multimodal data&quot;</span>

            <span class="n">flat_images</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">img_item</span> <span class="ow">in</span> <span class="n">all_images_valid</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">img_item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">flat_images</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">img_item</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">img_item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">flat_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_item</span><span class="p">)</span>

            <span class="n">flat_videos</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">vid_item</span> <span class="ow">in</span> <span class="n">all_videos_valid</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vid_item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">flat_videos</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">vid_item</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">vid_item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">flat_videos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vid_item</span><span class="p">)</span>

            <span class="n">processor_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">all_prompts_multimodal</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s2">&quot;add_special_tokens&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s2">&quot;max_length&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_max_len</span><span class="p">,</span>
                <span class="s2">&quot;truncation&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="n">flat_images</span><span class="p">:</span>
                <span class="n">processor_kwargs</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">flat_images</span>
            <span class="k">if</span> <span class="n">flat_videos</span><span class="p">:</span>
                <span class="n">processor_kwargs</span><span class="p">[</span><span class="s2">&quot;videos&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">flat_videos</span>

            <span class="n">inputs_multimodal</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">(</span><span class="o">**</span><span class="n">processor_kwargs</span><span class="p">)</span>

            <span class="n">all_prompt_token_ids_multimodal</span> <span class="o">=</span> <span class="n">inputs_multimodal</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
            <span class="n">all_images_pixel_values_multimodal</span> <span class="o">=</span> <span class="n">inputs_multimodal</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">all_videos_pixel_values_multimodal</span> <span class="o">=</span> <span class="n">inputs_multimodal</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pixel_values_videos&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

            <span class="n">all_images_grid_thw_multimodal</span> <span class="o">=</span> <span class="n">inputs_multimodal</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;image_grid_thw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">all_videos_grid_thw_multimodal</span> <span class="o">=</span> <span class="n">inputs_multimodal</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;video_grid_thw&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># ===== Stage 4: Merge back in original order =====</span>
        <span class="n">total_samples</span> <span class="o">=</span> <span class="n">L</span> <span class="o">*</span> <span class="n">N</span>
        <span class="n">all_prompts_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>
        <span class="n">all_images_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>
        <span class="n">all_videos_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>
        <span class="n">all_prompt_token_ids_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>
        <span class="n">all_images_grid_thw_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>
        <span class="n">all_videos_grid_thw_list</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">total_samples</span>

        <span class="c1"># 4-A: Fill text-only</span>
        <span class="n">text_ptr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">orig_idx</span> <span class="ow">in</span> <span class="n">text_idx</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">gid</span> <span class="o">=</span> <span class="n">orig_idx</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">n</span>
                <span class="n">all_prompts_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_prompts_text</span><span class="p">[</span><span class="n">text_ptr</span><span class="p">]</span>
                <span class="n">all_prompt_token_ids_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_prompt_token_ids_text</span><span class="p">[</span><span class="n">text_ptr</span><span class="p">]</span>
                <span class="c1"># Ensure (0, 3) shape for cat</span>
                <span class="n">all_images_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
                <span class="n">all_videos_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
                <span class="n">text_ptr</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># 4-B: Fill multimodal</span>
        <span class="n">multi_ptr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">image_grid_ptr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">video_grid_ptr</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">orig_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">orig_idx</span> <span class="ow">in</span> <span class="n">text_idx</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
                <span class="n">gid</span> <span class="o">=</span> <span class="n">orig_idx</span> <span class="o">*</span> <span class="n">N</span> <span class="o">+</span> <span class="n">n</span>
                <span class="n">all_prompts_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_prompts_multimodal</span><span class="p">[</span><span class="n">multi_ptr</span><span class="p">]</span>
                <span class="n">all_images_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_images_valid</span><span class="p">[</span><span class="n">multi_ptr</span><span class="p">]</span>
                <span class="n">all_videos_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_videos_valid</span><span class="p">[</span><span class="n">multi_ptr</span><span class="p">]</span>
                <span class="n">all_prompt_token_ids_out</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_prompt_token_ids_multimodal</span><span class="p">[</span><span class="n">multi_ptr</span><span class="p">]</span>

                <span class="c1"># Handle image_grid_thw: extract rows based on all_images_num</span>
                <span class="n">num_images</span> <span class="o">=</span> <span class="n">all_images_num</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">num_images</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">all_images_grid_thw_multimodal</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">all_images_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_images_grid_thw_multimodal</span><span class="p">[</span><span class="n">image_grid_ptr</span><span class="p">:</span><span class="n">image_grid_ptr</span> <span class="o">+</span>
                                                                                   <span class="n">num_images</span><span class="p">]</span>
                    <span class="n">image_grid_ptr</span> <span class="o">+=</span> <span class="n">num_images</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">all_images_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

                <span class="c1"># Handle video_grid_thw: extract rows based on all_videos_num</span>
                <span class="n">num_videos</span> <span class="o">=</span> <span class="n">all_videos_num</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">num_videos</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">all_videos_grid_thw_multimodal</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">all_videos_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_videos_grid_thw_multimodal</span><span class="p">[</span><span class="n">video_grid_ptr</span><span class="p">:</span><span class="n">video_grid_ptr</span> <span class="o">+</span>
                                                                                   <span class="n">num_videos</span><span class="p">]</span>
                    <span class="n">video_grid_ptr</span> <span class="o">+=</span> <span class="n">num_videos</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">all_videos_grid_thw_list</span><span class="p">[</span><span class="n">gid</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

                <span class="n">multi_ptr</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Concatenate grid_thw (using cat instead of stack to support multi-image/video)</span>
        <span class="n">all_images_grid_thw</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_images_grid_thw_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_images_grid_thw_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">all_videos_grid_thw</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_videos_grid_thw_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_videos_grid_thw_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Expand references</span>
        <span class="k">if</span> <span class="n">all_references</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_references</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">ref</span><span class="p">]</span> <span class="o">*</span> <span class="n">N</span> <span class="k">for</span> <span class="n">ref</span> <span class="ow">in</span> <span class="n">all_references</span><span class="p">],</span> <span class="p">[])</span>

        <span class="k">return</span> <span class="n">EasyDict</span><span class="p">(</span>
            <span class="n">all_prompt_token_ids</span><span class="o">=</span><span class="n">all_prompt_token_ids_out</span><span class="p">,</span>
            <span class="n">all_prompts</span><span class="o">=</span><span class="n">all_prompts_out</span><span class="p">,</span>
            <span class="n">all_images</span><span class="o">=</span><span class="n">all_images_out</span><span class="p">,</span>
            <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos_out</span><span class="p">,</span>
            <span class="n">all_images_num</span><span class="o">=</span><span class="n">all_images_num</span><span class="p">,</span>
            <span class="n">all_videos_num</span><span class="o">=</span><span class="n">all_videos_num</span><span class="p">,</span>
            <span class="n">all_images_pixel_values</span><span class="o">=</span><span class="n">all_images_pixel_values_multimodal</span><span class="p">,</span>
            <span class="n">all_videos_pixel_values</span><span class="o">=</span><span class="n">all_videos_pixel_values_multimodal</span><span class="p">,</span>
            <span class="n">all_images_grid_thw</span><span class="o">=</span><span class="n">all_images_grid_thw</span><span class="p">,</span>
            <span class="n">all_videos_grid_thw</span><span class="o">=</span><span class="n">all_videos_grid_thw</span><span class="p">,</span>
            <span class="n">all_references</span><span class="o">=</span><span class="n">all_references</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">RewardComputationEngine</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Manages reward model inference and score aggregation.</span>

<span class="sd">    This engine handles both local and remote reward models, supporting:</span>
<span class="sd">        - Remote HTTP/gRPC reward models</span>
<span class="sd">        - Local PyTorch reward models</span>
<span class="sd">        - Custom reward functions and rules</span>
<span class="sd">        - Multi-model ensemble with custom aggregation</span>
<span class="sd">        - Optimized batch processing with sample filtering</span>

<span class="sd">    The engine uses a three-stage pipeline:</span>
<span class="sd">        1. Gather: Collect or filter samples based on reward recipe</span>
<span class="sd">        2. Process: Run forward pass through reward model(s)</span>
<span class="sd">        3. Aggregate: Combine scores using reward_fn</span>

<span class="sd">    Args:</span>
<span class="sd">        reward_model: Single reward model or list of models</span>
<span class="sd">        remote_rm_url: List of remote reward model URLs</span>
<span class="sd">        custom_reward_func: Custom Python function for reward computation</span>
<span class="sd">        reward_fn: Aggregation function for multiple reward models</span>
<span class="sd">        reward_fn_label_map: Mapping from reward model names to indices</span>
<span class="sd">        tokenizer: Tokenizer for decoding sequences</span>
<span class="sd">        strategy: Training strategy (for model loading/offloading)</span>
<span class="sd">        packing_samples: Whether samples are packed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reward_model</span><span class="p">,</span>
        <span class="n">remote_rm_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">custom_reward_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">],</span>
        <span class="n">reward_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">],</span>
        <span class="n">reward_fn_label_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">reward_recipe</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">strategy</span><span class="p">,</span>
        <span class="n">packing_samples</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the reward computation engine.</span>

<span class="sd">        :param reward_model: Single reward model or list of models</span>
<span class="sd">        :type reward_model: Union[torch.nn.Module, List[torch.nn.Module]]</span>
<span class="sd">        :param remote_rm_url: List of remote reward model URLs</span>
<span class="sd">        :type remote_rm_url: Optional[List[str]]</span>
<span class="sd">        :param custom_reward_func: Custom Python function for reward computation</span>
<span class="sd">        :type custom_reward_func: Optional[Callable]</span>
<span class="sd">        :param reward_fn: Aggregation function for multiple reward models</span>
<span class="sd">        :type reward_fn: Optional[Callable]</span>
<span class="sd">        :param reward_fn_label_map: Mapping from reward model names to indices</span>
<span class="sd">        :type reward_fn_label_map: Optional[Dict[str, int]]</span>
<span class="sd">        :param reward_recipe: Recipe configuration for reward computation</span>
<span class="sd">        :type reward_recipe: Optional[Dict]</span>
<span class="sd">        :param tokenizer: Tokenizer for decoding sequences</span>
<span class="sd">        :type tokenizer: transformers.PreTrainedTokenizer</span>
<span class="sd">        :param strategy: Training strategy (for model loading/offloading)</span>
<span class="sd">        :type strategy: Any</span>
<span class="sd">        :param packing_samples: Whether samples are packed</span>
<span class="sd">        :type packing_samples: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span> <span class="o">=</span> <span class="n">reward_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remote_rm_url</span> <span class="o">=</span> <span class="n">remote_rm_url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">custom_reward_func</span> <span class="o">=</span> <span class="n">custom_reward_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span> <span class="o">=</span> <span class="n">reward_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn_label_map</span> <span class="o">=</span> <span class="n">reward_fn_label_map</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_recipe</span> <span class="o">=</span> <span class="n">reward_recipe</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span> <span class="o">=</span> <span class="n">strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span> <span class="o">=</span> <span class="n">packing_samples</span>

        <span class="c1"># Build inverse label map for quick lookup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inv_label_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">idx</span><span class="p">:</span> <span class="n">key</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn_label_map</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="c1"># Configuration flag for optimized filtering engine</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_filtering_engine</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># TODO: Enable after testing</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">vlm_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards for all samples and store in outputs[i].rewards.</span>

<span class="sd">        This method dispatches to the appropriate computation path based on</span>
<span class="sd">        whether remote or local reward models are used.</span>

<span class="sd">        :param outputs: List of sample outputs to compute rewards for</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param vlm_mode: Whether in vision-language mode</span>
<span class="sd">        :type vlm_mode: bool</span>
<span class="sd">        :param device: Device to place reward tensors on</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">remote_rm_url</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compute_remote_rewards</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compute_local_rewards</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_remote_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">vlm_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards using remote reward models.</span>

<span class="sd">        This path maintains serial processing for compatibility with HTTP/gRPC APIs.</span>

<span class="sd">        :param outputs: Sample outputs to compute rewards for</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param vlm_mode: Vision-language mode flag</span>
<span class="sd">        :type vlm_mode: bool</span>
<span class="sd">        :param device: Target device for tensors</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="c1"># Decode sequences to text</span>
            <span class="n">sequences</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">output</span><span class="o">.</span><span class="n">sequences</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span> <span class="k">else</span> <span class="n">unpacking_samples</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">reward_tensors</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Custom reward function</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_reward_func</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">vlm_mode</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_reward_func</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">references</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">custom_reward_func</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
                <span class="n">reward_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

            <span class="c1"># Remote reward models</span>
            <span class="k">for</span> <span class="n">rm_url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">remote_rm_url</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">reward_tensors</span><span class="p">):]:</span>
                <span class="k">if</span> <span class="n">vlm_mode</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="n">remote_rm_fn</span><span class="p">(</span>
                        <span class="n">rm_url</span><span class="p">,</span>
                        <span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span>
                        <span class="n">prompts</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span>
                        <span class="n">references</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">references</span><span class="p">,</span>
                        <span class="n">raw_images</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">raw_images</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="n">remote_rm_fn</span><span class="p">(</span>
                        <span class="n">rm_url</span><span class="p">,</span>
                        <span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span>
                        <span class="n">prompts</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">prompts</span><span class="p">,</span>
                        <span class="n">labels</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">reward_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

            <span class="c1"># Aggregate rewards</span>
            <span class="n">output</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span><span class="n">reward_tensors</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">reward_tensors</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">reward_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_local_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">vlm_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards using local reward models.</span>

<span class="sd">        Implements batched processing for efficiency. Supports both standard</span>
<span class="sd">        PyTorch models and custom engine models with optional sample filtering.</span>

<span class="sd">        :param outputs: Sample outputs to compute rewards for</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param vlm_mode: Vision-language mode flag</span>
<span class="sd">        :type vlm_mode: bool</span>
<span class="sd">        :param device: Target device for tensors</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Ensure reward_model is a list</span>
        <span class="n">is_multi_rm</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
        <span class="n">rm_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_multi_rm</span> <span class="k">else</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">]</span>

        <span class="c1"># Load all PyTorch models to GPU</span>
        <span class="k">for</span> <span class="n">rm</span> <span class="ow">in</span> <span class="n">rm_list</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reload_model</span><span class="p">(</span><span class="n">rm</span><span class="p">)</span>

        <span class="c1"># Compute rewards for each RM</span>
        <span class="c1"># all_rewards_list[rm_idx][micro_batch_idx] = Tensor(batch_size,)</span>
        <span class="n">all_rewards_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">rm_idx</span><span class="p">,</span> <span class="n">rm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rm_list</span><span class="p">):</span>
            <span class="n">micro_batch_rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_single_rm_rewards</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">rm_idx</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="n">all_rewards_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">micro_batch_rewards</span><span class="p">)</span>

            <span class="c1"># Offload model immediately after use</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">offload_model</span><span class="p">(</span><span class="n">rm</span><span class="p">)</span>

        <span class="c1"># Aggregate rewards across RMs for each micro-batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_aggregate_rewards</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">all_rewards_list</span><span class="p">,</span> <span class="n">is_multi_rm</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_single_rm_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rm</span><span class="p">,</span>
        <span class="n">rm_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">vlm_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards for a single reward model across all micro-batches.</span>

<span class="sd">        :param rm: Reward model instance</span>
<span class="sd">        :type rm: Union[torch.nn.Module, Any]</span>
<span class="sd">        :param rm_idx: Index of this RM in the RM list</span>
<span class="sd">        :type rm_idx: int</span>
<span class="sd">        :param outputs: Sample outputs</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param vlm_mode: Vision-language mode flag</span>
<span class="sd">        :type vlm_mode: bool</span>
<span class="sd">        :param device: Target device</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        :return: List of reward tensors, one per micro-batch</span>
<span class="sd">        :rtype: List[torch.Tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if this is a custom engine model (non-torch base_model)</span>
        <span class="n">is_custom_engine</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="s2">&quot;base_model&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm</span><span class="o">.</span><span class="n">base_model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_custom_engine</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_filtering_engine</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_filtered_rewards</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">rm_idx</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_custom_engine</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_batched_custom_engine_rewards</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_standard_torch_rewards</span><span class="p">(</span><span class="n">rm</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported reward model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">rm</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_filtered_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rm</span><span class="p">,</span>
        <span class="n">rm_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards using optimized filtering (only process relevant samples).</span>

<span class="sd">        This optimization filters samples based on the reward recipe, only running</span>
<span class="sd">        the forward pass on samples that actually need this specific RM.</span>

<span class="sd">        :param rm: Custom engine reward model</span>
<span class="sd">        :type rm: Any</span>
<span class="sd">        :param rm_idx: RM index for label lookup</span>
<span class="sd">        :type rm_idx: int</span>
<span class="sd">        :param outputs: Sample outputs</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param device: Target device</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        :return: List of reward tensors per micro-batch</span>
<span class="sd">        :rtype: List[torch.Tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get RM key from inverse label map</span>
        <span class="n">rm_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inv_label_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">rm_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">rm_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Filtering engine requires a label map key for RM at index </span><span class="si">{</span><span class="n">rm_idx</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but none was found. Check your reward_fn_label_map configuration.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># ========== Gather Stage: Filter samples that need this RM ==========</span>
        <span class="n">flat_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;prompt_and_output&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;raw_images&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;image_num&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;references&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="p">}</span>
        <span class="n">needed_positions</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># [(micro_batch_idx, sample_idx), ...]</span>

        <span class="k">for</span> <span class="n">mb_idx</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">samp_idx</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">):</span>
                <span class="c1"># Check if this sample&#39;s recipe requires this RM</span>
                <span class="n">needs_rm</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
                    <span class="n">typ</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span> <span class="ow">and</span> <span class="n">key</span> <span class="o">==</span> <span class="n">rm_key</span> <span class="ow">and</span> <span class="nb">float</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">0.0</span>
                    <span class="k">for</span> <span class="n">typ</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_recipe</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">[])</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">needs_rm</span><span class="p">:</span>
                    <span class="n">needed_positions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mb_idx</span><span class="p">,</span> <span class="n">samp_idx</span><span class="p">))</span>
                    <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;prompt_and_output&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_and_output</span><span class="p">[</span><span class="n">samp_idx</span><span class="p">])</span>
                    <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;raw_images&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">raw_images</span><span class="p">[</span><span class="n">samp_idx</span><span class="p">])</span>
                    <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;image_num&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">image_num</span><span class="p">[</span><span class="n">samp_idx</span><span class="p">])</span>
                    <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;references&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">references</span><span class="p">[</span><span class="n">samp_idx</span><span class="p">])</span>
                    <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">samp_idx</span><span class="p">])</span>

        <span class="c1"># ========== Process Stage: Compute or skip ==========</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">needed_positions</span><span class="p">:</span>
            <span class="c1"># No samples need this RM, return zeros for all micro-batches</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="c1"># Run single forward pass on filtered samples</span>
        <span class="n">rm_output</span> <span class="o">=</span> <span class="n">rm</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">prompt_and_outputs</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;prompt_and_output&quot;</span><span class="p">],</span>
            <span class="n">raw_images</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;raw_images&quot;</span><span class="p">],</span>
            <span class="n">img_num</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;image_num&quot;</span><span class="p">],</span>
            <span class="n">references</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;references&quot;</span><span class="p">],</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">filtered_scores</span> <span class="o">=</span> <span class="p">(</span><span class="n">rm_output</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">rm_output</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># ========== Scatter Stage: Reconstruct micro-batch structure ==========</span>
        <span class="n">micro_batch_rewards</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span>
        <span class="p">]</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">mb_idx</span><span class="p">,</span> <span class="n">samp_idx</span><span class="p">),</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">needed_positions</span><span class="p">,</span> <span class="n">filtered_scores</span><span class="p">):</span>
            <span class="n">micro_batch_rewards</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">][</span><span class="n">samp_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>

        <span class="k">return</span> <span class="n">micro_batch_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_batched_custom_engine_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rm</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>  <span class="c1"># noqa: ARG002 (unused but kept for API consistency)</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards using custom engine with full batch processing (legacy path).</span>

<span class="sd">        :param rm: Custom engine reward model</span>
<span class="sd">        :type rm: Any</span>
<span class="sd">        :param outputs: Sample outputs</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param device: Target device (unused but kept for API consistency)</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        :return: List of reward tensors per micro-batch</span>
<span class="sd">        :rtype: List[torch.Tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Flatten all micro-batches into single batch</span>
        <span class="n">flat_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;prompt_and_output&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;raw_images&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;image_num&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;references&quot;</span><span class="p">:</span> <span class="p">[],</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="p">}</span>

        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;prompt_and_output&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_and_output</span><span class="p">)</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;raw_images&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">raw_images</span><span class="p">)</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;image_num&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">image_num</span><span class="p">)</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;references&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">references</span><span class="p">)</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>

        <span class="c1"># Single forward pass</span>
        <span class="n">rm_output</span> <span class="o">=</span> <span class="n">rm</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">prompt_and_outputs</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;prompt_and_output&quot;</span><span class="p">],</span>
            <span class="n">raw_images</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;raw_images&quot;</span><span class="p">],</span>
            <span class="n">img_num</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;image_num&quot;</span><span class="p">],</span>
            <span class="n">references</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;references&quot;</span><span class="p">],</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">flat_data</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">all_scores</span> <span class="o">=</span> <span class="n">rm_output</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">rm_output</span>

        <span class="c1"># Split back into micro-batches</span>
        <span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_and_output</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">all_scores</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_standard_torch_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rm</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">vlm_mode</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>  <span class="c1"># noqa: ARG002 (kept for future VLM-specific logic)</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute rewards using standard PyTorch reward model.</span>

<span class="sd">        Processes each micro-batch sequentially.</span>

<span class="sd">        :param rm: PyTorch reward model</span>
<span class="sd">        :type rm: torch.nn.Module</span>
<span class="sd">        :param outputs: Sample outputs</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param vlm_mode: Vision-language mode flag (reserved for future use)</span>
<span class="sd">        :type vlm_mode: bool</span>
<span class="sd">        :param device: Target device</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        :return: List of reward tensors per micro-batch</span>
<span class="sd">        :rtype: List[torch.Tensor]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">micro_batch_rewards</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="c1"># Unpack sequences if needed</span>
            <span class="n">sequences</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">output</span><span class="o">.</span><span class="n">sequences</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span> <span class="k">else</span> <span class="n">unpacking_samples</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Forward pass</span>
            <span class="n">rm_output</span> <span class="o">=</span> <span class="n">rm</span><span class="p">(</span>
                <span class="n">sequences</span><span class="p">,</span>
                <span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">prompt_and_output</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_and_output</span><span class="p">,</span>
                <span class="n">raw_images</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">raw_images</span><span class="p">,</span>
                <span class="n">img_num</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">image_num</span><span class="p">,</span>
                <span class="o">**</span><span class="n">output</span><span class="o">.</span><span class="n">inputs_extra_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">score</span> <span class="o">=</span> <span class="n">rm_output</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rm_output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">rm_output</span>
            <span class="n">micro_batch_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">micro_batch_rewards</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_aggregate_rewards</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_SamplesOutput</span><span class="p">],</span>
        <span class="n">all_rewards_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">is_multi_rm</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Aggregate rewards from multiple RMs and store in outputs.</span>

<span class="sd">        :param outputs: Sample outputs (modified in-place)</span>
<span class="sd">        :type outputs: List[_SamplesOutput]</span>
<span class="sd">        :param all_rewards_list: Nested list [rm_idx][micro_batch_idx] -&gt; Tensor</span>
<span class="sd">        :type all_rewards_list: List[List[torch.Tensor]]</span>
<span class="sd">        :param is_multi_rm: Whether using multiple reward models</span>
<span class="sd">        :type is_multi_rm: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_micro_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">num_rms</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_rewards_list</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">mb_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_micro_batches</span><span class="p">):</span>
            <span class="c1"># Collect rewards from all RMs for this micro-batch</span>
            <span class="n">same_batch_rewards</span> <span class="o">=</span> <span class="p">[</span><span class="n">all_rewards_list</span><span class="p">[</span><span class="n">rm_idx</span><span class="p">][</span><span class="n">mb_idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">rm_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_rms</span><span class="p">)]</span>

            <span class="k">if</span> <span class="n">is_multi_rm</span><span class="p">:</span>
                <span class="c1"># Use custom aggregation function</span>
                <span class="n">sequences</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sequences</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span> <span class="k">else</span>
                    <span class="n">unpacking_samples</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">queries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">rewards</span><span class="p">,</span> <span class="n">reward_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">(</span>
                    <span class="n">model_reward_list</span><span class="o">=</span><span class="n">same_batch_rewards</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">labels</span><span class="p">,</span>
                    <span class="n">queries</span><span class="o">=</span><span class="n">queries</span><span class="p">,</span>
                    <span class="n">refs</span><span class="o">=</span><span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">references</span><span class="p">,</span>
                    <span class="n">label_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_fn_label_map</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reward_metrics</span> <span class="o">=</span> <span class="n">reward_metrics</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Single RM, use score directly</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">same_batch_rewards</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">mb_idx</span><span class="p">]</span><span class="o">.</span><span class="n">reward_metrics</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># ============================================================================</span>
<span class="c1"># Main Experience Maker</span>
<span class="c1"># ============================================================================</span>


<div class="viewcode-block" id="FastExperienceMaker"><a class="viewcode-back" href="../../../api_doc/trainer/fast_exp_maker.html#lightrft.trainer.fast_exp_maker.FastExperienceMaker">[docs]</a><span class="k">class</span><span class="w"> </span><span class="nc">FastExperienceMaker</span><span class="p">(</span><span class="n">NaiveExperienceMaker</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Optimized experience maker with VLLM/SGLang support and advanced RL features.</span>

<span class="sd">    This class extends NaiveExperienceMaker to provide:</span>
<span class="sd">        - High-performance inference via VLLM or SGLang backends</span>
<span class="sd">        - Multimodal (vision-language) data processing</span>
<span class="sd">        - Multiple advantage estimation algorithms (GAE, RLOO, REINFORCE, Group Norm)</span>
<span class="sd">        - Flexible reward model composition with custom aggregation</span>
<span class="sd">        - Sample packing for improved training efficiency</span>
<span class="sd">        - Running reward normalization and advantage whitening/clipping</span>

<span class="sd">    The experience generation pipeline:</span>
<span class="sd">        1. Sample Generation: Use inference engine to generate responses</span>
<span class="sd">        2. Shard-Parallel Preprocessing: Distribute samples across shards</span>
<span class="sd">        3. Model Inference: Batch forward through actor, critic, initial, and reward models</span>
<span class="sd">        4. Shard-Parallel Postprocessing: Gather results back</span>
<span class="sd">        5. Reward Processing: Apply transformations (normalization, shaping, filtering)</span>
<span class="sd">        6. Advantage Estimation: Compute advantages and returns</span>

<span class="sd">    Args:</span>
<span class="sd">        packing_samples: Whether to pack multiple sequences into single batch</span>
<span class="sd">        processor: Multimodal processor for vision-language models</span>
<span class="sd">        *args, **kwargs: Arguments passed to parent NaiveExperienceMaker</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="FastExperienceMaker.__init__"><a class="viewcode-back" href="../../../api_doc/trainer/fast_exp_maker.html#lightrft.trainer.fast_exp_maker.FastExperienceMaker.__init__">[docs]</a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">packing_samples</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize FastExperienceMaker.</span>

<span class="sd">        :param args: Positional arguments for NaiveExperienceMaker</span>
<span class="sd">        :type args: tuple</span>
<span class="sd">        :param packing_samples: Enable sample packing for efficiency</span>
<span class="sd">        :type packing_samples: bool</span>
<span class="sd">        :param processor: Multimodal processor (required for VLM models)</span>
<span class="sd">        :type processor: Optional[Any]</span>
<span class="sd">        :param kwargs: Keyword arguments for NaiveExperienceMaker</span>
<span class="sd">        :type kwargs: dict</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Core configuration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend_mp_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">engine_mp_group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">engine_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span> <span class="o">=</span> <span class="n">packing_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">processor</span>

        <span class="c1"># Initialize tokenizer (extract from processor if needed)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">)</span>

        <span class="c1"># Initialize running reward normalization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">reward_running_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span> <span class="o">=</span> <span class="n">RunningMoments</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Initialize advantage calculator</span>
        <span class="n">advantage_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">advantage_estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">advantage_calculator</span> <span class="o">=</span> <span class="n">get_advantage_calculator</span><span class="p">(</span><span class="n">advantage_estimator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="c1"># Initialize helper modules</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="o">=</span> <span class="n">MultimodalDataProcessor</span><span class="p">(</span>
                <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">processor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
                <span class="n">prompt_max_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_max_len</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward_engine</span> <span class="o">=</span> <span class="n">RewardComputationEngine</span><span class="p">(</span>
            <span class="n">reward_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_model</span><span class="p">,</span>
            <span class="n">remote_rm_url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">remote_rm_url</span><span class="p">,</span>
            <span class="n">custom_reward_func</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;custom_reward_func&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">reward_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_fn</span><span class="p">,</span>
            <span class="n">reward_fn_label_map</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_fn_label_map&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">reward_recipe</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;reward_recipe&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">strategy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="p">,</span>
            <span class="n">packing_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Cache actor&#39;s supported parameters based on its modality</span>
        <span class="c1"># Default to VISION_LANGUAGE for backward compatibility with models without modality attribute</span>
        <span class="n">actor_modality</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">modality</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_actor_supported_params</span> <span class="o">=</span> <span class="n">get_supported_parameters</span><span class="p">(</span><span class="n">actor_modality</span><span class="p">)</span></div>

    <span class="c1"># ========================================================================</span>
    <span class="c1"># Public API Methods</span>
    <span class="c1"># ========================================================================</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">make_experience_list</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">all_prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">all_images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_videos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a list of experiences from prompts and optional multimodal inputs.</span>

<span class="sd">        This is the main entry point for experience generation. It orchestrates the</span>
<span class="sd">        entire pipeline from sampling to advantage computation.</span>

<span class="sd">        :param all_prompts: List of text prompts</span>
<span class="sd">        :type all_prompts: List[str]</span>
<span class="sd">        :param all_images: Optional images for multimodal generation</span>
<span class="sd">        :type all_images: Optional[List]</span>
<span class="sd">        :param all_references: Optional reference texts for evaluation</span>
<span class="sd">        :type all_references: Optional[List[str]]</span>
<span class="sd">        :param all_labels: Optional labels for samples</span>
<span class="sd">        :type all_labels: Optional[List]</span>
<span class="sd">        :param all_videos: Optional videos for multimodal generation</span>
<span class="sd">        :type all_videos: Optional[List]</span>
<span class="sd">        :param generate_kwargs: Generation parameters (temperature, max_new_tokens, etc.)</span>
<span class="sd">        :type generate_kwargs: dict</span>
<span class="sd">        :return: List of Experience or ExperienceVL objects with computed advantages and returns</span>
<span class="sd">        :rtype: List[Union[Experience, ExperienceVL]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>

        <span class="c1"># Normalize images if provided</span>
        <span class="k">if</span> <span class="n">all_images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Multimodal data (images) provided but processor was not initialized. &quot;</span>
                    <span class="s2">&quot;Please provide a processor when initializing FastExperienceMaker for VLM support.&quot;</span>
                <span class="p">)</span>
            <span class="n">all_images</span> <span class="o">=</span> <span class="n">normalize_images</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span>

        <span class="c1"># Normalize videos if provided</span>
        <span class="k">if</span> <span class="n">all_videos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Multimodal data (videos) provided but processor was not initialized. &quot;</span>
                    <span class="s2">&quot;Please provide a processor when initializing FastExperienceMaker for VLM support.&quot;</span>
                <span class="p">)</span>
            <span class="n">all_videos</span> <span class="o">=</span> <span class="n">normalize_videos</span><span class="p">(</span><span class="n">all_videos</span><span class="p">)</span>

        <span class="c1"># Get image counts</span>
        <span class="n">images_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">get_images_num</span><span class="p">(</span><span class="n">all_images</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="ow">and</span> <span class="n">all_images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Get video counts</span>
        <span class="n">videos_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">get_videos_num</span><span class="p">(</span><span class="n">all_videos</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span> <span class="ow">and</span> <span class="n">all_videos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># ========== Stage 1: Sample Generation ==========</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;  generate_samples&#39;</span><span class="p">)</span>
        <span class="n">samples_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span>
            <span class="n">all_prompts</span><span class="p">,</span>
            <span class="n">all_images</span><span class="o">=</span><span class="n">all_images</span><span class="p">,</span>
            <span class="n">images_num</span><span class="o">=</span><span class="n">images_num</span><span class="p">,</span>
            <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos</span><span class="p">,</span>
            <span class="n">videos_num</span><span class="o">=</span><span class="n">videos_num</span><span class="p">,</span>
            <span class="n">all_references</span><span class="o">=</span><span class="n">all_references</span><span class="p">,</span>
            <span class="n">all_labels</span><span class="o">=</span><span class="n">all_labels</span><span class="p">,</span>
            <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s1">&#39;  generate_samples&#39;</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">barrier</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

        <span class="c1"># ========== Stage 2: Shard-Parallel Preprocessing ==========</span>
        <span class="n">all_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">sp_data_processor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">samples_list</span><span class="p">)</span>

        <span class="c1"># ========== Stage 3: Model Inference ==========</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;  make_experience&#39;</span><span class="p">)</span>
        <span class="n">experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_experience_list_by_model</span><span class="p">(</span><span class="n">all_samples</span><span class="p">)</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s1">&#39;  make_experience&#39;</span><span class="p">)</span>

        <span class="c1"># ========== Stage 4: Shard-Parallel Postprocessing ==========</span>
        <span class="n">experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">sp_data_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">experiences</span><span class="p">)</span>

        <span class="c1"># ========== Stage 5: Reward Processing ==========</span>
        <span class="n">experiences</span><span class="p">,</span> <span class="n">rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_experiences</span><span class="p">(</span>  <span class="c1"># GRPO&#39;s -mean / std operation is performed in this method</span>
            <span class="n">experiences</span><span class="p">,</span> <span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_new_tokens&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># ========== Stage 6: Multi-Image/Video Handling ==========</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">num</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">images_num</span><span class="p">))</span> <span class="ow">or</span> \
           <span class="p">(</span><span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">num</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">videos_num</span><span class="p">)):</span>
            <span class="c1"># Expand image_num by n_samples_per_prompt</span>
            <span class="n">expanded_images_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">num</span><span class="p">]</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">n_samples_per_prompt</span>
                                       <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">images_num</span><span class="p">],</span> <span class="p">[])</span> <span class="k">if</span> <span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="n">expanded_videos_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">num</span><span class="p">]</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">n_samples_per_prompt</span>
                                       <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">videos_num</span><span class="p">],</span> <span class="p">[])</span> <span class="k">if</span> <span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_process_multi_image_video_thws</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="n">expanded_images_num</span><span class="p">,</span> <span class="n">expanded_videos_num</span><span class="p">)</span>

        <span class="c1"># ========== Stage 7: Advantage Computation ==========</span>
        <span class="n">experiences</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_advantages_and_returns</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">generate_kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">experiences</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_samples</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">all_prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">all_images</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_videos</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">images_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">videos_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">all_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">generate_kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Samples</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate samples using the inference engine (VLLM or SGLang).</span>

<span class="sd">        This method handles:</span>
<span class="sd">            - Sampling parameter configuration</span>
<span class="sd">            - Multimodal data processing</span>
<span class="sd">            - Inference engine invocation</span>
<span class="sd">            - Output processing into Samples format</span>

<span class="sd">        :param all_prompts: List of text prompts</span>
<span class="sd">        :type all_prompts: List[str]</span>
<span class="sd">        :param all_images: Optional images for VLM</span>
<span class="sd">        :type all_images: Optional[List]</span>
<span class="sd">        :param images_num: Number of images per prompt</span>
<span class="sd">        :type images_num: Optional[List[int]]</span>
<span class="sd">        :param all_references: Reference texts</span>
<span class="sd">        :type all_references: Optional[List[str]]</span>
<span class="sd">        :param all_labels: Sample labels</span>
<span class="sd">        :type all_labels: Optional[List]</span>
<span class="sd">        :param all_videos: Optional videos for VLM</span>
<span class="sd">        :type all_videos: Optional[List]</span>
<span class="sd">        :param videos_num: Number of videos per prompt</span>
<span class="sd">        :type videos_num: Optional[List[int]]</span>
<span class="sd">        :param generate_kwargs: Generation parameters (temperature, max_new_tokens, etc.)</span>
<span class="sd">        :type generate_kwargs: dict</span>
<span class="sd">        :return: List of Samples or SamplesVL objects</span>
<span class="sd">        :rtype: List[Union[Samples, SamplesVL]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">inference_engine</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Inference engine required&quot;</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>
        <span class="n">is_multimodal</span> <span class="o">=</span> <span class="n">all_images</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">all_videos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">n_samples_per_prompt</span>

        <span class="c1"># Initialize multimodal-specific variables to None</span>
        <span class="n">all_images_num</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_videos_num</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_images_pixel_values</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_videos_pixel_values</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_images_grid_thw</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">all_videos_grid_thw</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># ========== Configure Sampling Parameters ==========</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">engine_type</span> <span class="o">==</span> <span class="s2">&quot;vllm&quot;</span><span class="p">:</span>
            <span class="c1"># For vllm&gt;=0.13.0, truncate_prompt_tokens must not exceed max_model_len</span>
            <span class="c1"># For older versions, we can use 8192 directly without validation</span>
            <span class="k">if</span> <span class="n">vllm_ge_0130</span><span class="p">():</span>
                <span class="n">max_model_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">inference_engine</span><span class="o">.</span><span class="n">llm_engine</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">max_model_len</span>
                <span class="n">truncate_tokens</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">8192</span><span class="p">,</span> <span class="n">max_model_len</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">truncate_tokens</span> <span class="o">=</span> <span class="mi">8192</span>

            <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;top_p&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;top_k&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">max_tokens</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_new_tokens&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
                <span class="n">min_tokens</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_new_tokens&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;skip_special_tokens&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">include_stop_str_in_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">ignore_eos</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;IGNORE_EOS&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
                <span class="n">truncate_prompt_tokens</span><span class="o">=</span><span class="n">truncate_tokens</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">engine_type</span> <span class="o">==</span> <span class="s2">&quot;sglang&quot;</span><span class="p">:</span>
            <span class="n">sampling_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;top_p&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;top_k&quot;</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_new_tokens&quot;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
                <span class="n">presence_penalty</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">frequency_penalty</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                <span class="n">skip_special_tokens</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;skip_special_tokens&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">spaces_between_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">ignore_eos</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;IGNORE_EOS&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported engine type: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># ========== Expand Labels ==========</span>
        <span class="k">if</span> <span class="n">all_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_labels</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">label</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">all_labels</span><span class="p">],</span> <span class="p">[])</span>

        <span class="c1"># ========== Process Multimodal Data ==========</span>
        <span class="k">if</span> <span class="n">is_multimodal</span><span class="p">:</span>
            <span class="n">processed_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multimodal_processor</span><span class="o">.</span><span class="n">process_multimodal_batch</span><span class="p">(</span>
                <span class="n">all_prompts</span><span class="o">=</span><span class="n">all_prompts</span><span class="p">,</span>
                <span class="n">all_images</span><span class="o">=</span><span class="n">all_images</span><span class="p">,</span>
                <span class="n">all_references</span><span class="o">=</span><span class="n">all_references</span><span class="p">,</span>
                <span class="n">images_num</span><span class="o">=</span><span class="n">images_num</span><span class="p">,</span>
                <span class="n">n_samples_per_prompt</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
                <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos</span><span class="p">,</span>
                <span class="n">videos_num</span><span class="o">=</span><span class="n">videos_num</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">all_prompt_token_ids</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_prompt_token_ids&quot;</span><span class="p">]</span>
            <span class="n">all_prompts</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_prompts&quot;</span><span class="p">]</span>
            <span class="n">all_images</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_images&quot;</span><span class="p">]</span>
            <span class="n">all_videos</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_videos&quot;</span><span class="p">]</span>
            <span class="n">all_images_num</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_images_num&quot;</span><span class="p">]</span>
            <span class="n">all_videos_num</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_videos_num&quot;</span><span class="p">]</span>
            <span class="n">all_images_grid_thw</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_images_grid_thw&quot;</span><span class="p">]</span>
            <span class="n">all_videos_grid_thw</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_videos_grid_thw&quot;</span><span class="p">]</span>
            <span class="n">all_images_pixel_values</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_images_pixel_values&quot;</span><span class="p">]</span>
            <span class="n">all_videos_pixel_values</span> <span class="o">=</span> <span class="n">processed_data</span><span class="p">[</span><span class="s2">&quot;all_videos_pixel_values&quot;</span><span class="p">]</span>
            <span class="n">all_references</span> <span class="o">=</span> <span class="n">processed_data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;all_references&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Text-only processing</span>
            <span class="n">tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize_fn</span><span class="p">(</span><span class="n">all_prompts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">all_prompt_token_ids</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([[</span><span class="n">token_ids</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_samples</span> <span class="k">for</span> <span class="n">token_ids</span> <span class="ow">in</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]],</span> <span class="p">[])</span>

        <span class="c1"># ========== Generate via Inference Engine ==========</span>
        <span class="c1"># Call fire_sampling function or direct generation</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="p">,</span> <span class="s1">&#39;use_fire&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">use_fire</span><span class="p">:</span>
                <span class="c1"># Use FIRE sampling (Flaming-hot Initiation with Regular Execution)</span>
                <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">fire_sampling</span><span class="p">(</span>
                    <span class="n">all_prompt_token_ids</span><span class="o">=</span><span class="n">all_prompt_token_ids</span><span class="p">,</span>
                    <span class="n">generate_fn</span><span class="o">=</span><span class="n">generate_fn</span><span class="p">,</span>  <span class="c1"># noqa: TODO</span>
                    <span class="n">engine_type</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">engine_type</span><span class="p">,</span>
                    <span class="n">first_token_temperature</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;first_token_temperature&quot;</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">),</span>
                    <span class="n">temperature</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                    <span class="n">first_token_top_k</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;first_token_top_k&quot;</span><span class="p">,</span> <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_k</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">,</span> <span class="s1">&#39;top_k&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
                    <span class="p">),</span>
                    <span class="n">first_token_top_p</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                        <span class="s2">&quot;first_token_top_p&quot;</span><span class="p">,</span> <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_p</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">sampling_params</span><span class="p">,</span> <span class="s1">&#39;top_p&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="mf">1.0</span>
                    <span class="p">),</span>
                    <span class="n">is_multimodal</span><span class="o">=</span><span class="n">is_multimodal</span><span class="p">,</span>
                    <span class="n">all_prompts</span><span class="o">=</span><span class="n">all_prompts</span><span class="p">,</span>
                    <span class="n">all_images</span><span class="o">=</span><span class="n">all_images</span><span class="p">,</span>
                    <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos</span><span class="p">,</span>
                    <span class="n">all_images_num</span><span class="o">=</span><span class="n">all_images_num</span><span class="p">,</span>
                    <span class="n">all_videos_num</span><span class="o">=</span><span class="n">all_videos_num</span><span class="p">,</span>
                    <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># maybe this can be called in if and else respectively? or like this?</span>
                <span class="c1"># Use original single-shot generation</span>
                <span class="n">all_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">gather_and_generate</span><span class="p">(</span>
                    <span class="n">sampling_params</span><span class="o">=</span><span class="n">sampling_params</span><span class="p">,</span>
                    <span class="n">all_prompt_token_ids</span><span class="o">=</span><span class="n">all_prompt_token_ids</span><span class="p">,</span>
                    <span class="n">all_prompts</span><span class="o">=</span><span class="n">all_prompts</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">sleep_engine</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">enable_engine_sleep</span><span class="p">,</span>
                    <span class="n">all_images</span><span class="o">=</span><span class="n">all_images</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">all_videos</span><span class="o">=</span><span class="n">all_videos</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">images_num</span><span class="o">=</span><span class="n">all_images_num</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">videos_num</span><span class="o">=</span><span class="n">all_videos_num</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;prompt&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;too long&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Skip] </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># Return None, subsequent experience_maker will ignore</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span>

        <span class="c1"># ========== Process Outputs into Samples ==========</span>
        <span class="n">samples_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">image_patch_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">video_patch_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">image_start_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">video_start_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">):</span>
            <span class="n">micro_batch_outputs</span> <span class="o">=</span> <span class="n">all_outputs</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span>
            <span class="n">micro_batch_prompts</span> <span class="o">=</span> <span class="n">all_prompts</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span>

            <span class="c1"># Extract micro-batch data</span>
            <span class="n">micro_batch_grid_thw</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">micro_batch_video_grid_thw</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">micro_batch_raw_images</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">is_multimodal</span><span class="p">:</span>
                <span class="n">rollout_image_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">all_images_num</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">])</span>
                <span class="n">micro_batch_grid_thw</span> <span class="o">=</span> <span class="n">all_images_grid_thw</span><span class="p">[</span><span class="n">image_start_idx</span><span class="p">:</span><span class="n">image_start_idx</span> <span class="o">+</span> <span class="n">rollout_image_count</span><span class="p">]</span>
                <span class="n">micro_batch_raw_images</span> <span class="o">=</span> <span class="n">all_images</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span>
                <span class="n">image_start_idx</span> <span class="o">+=</span> <span class="n">rollout_image_count</span>

                <span class="n">rollout_video_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">all_videos_num</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">])</span>
                <span class="n">micro_batch_video_grid_thw</span> <span class="o">=</span> <span class="n">all_videos_grid_thw</span><span class="p">[</span><span class="n">video_start_idx</span><span class="p">:</span><span class="n">video_start_idx</span> <span class="o">+</span> <span class="n">rollout_video_count</span><span class="p">]</span>
                <span class="n">video_start_idx</span> <span class="o">+=</span> <span class="n">rollout_video_count</span>

            <span class="n">micro_batch_references</span> <span class="o">=</span> <span class="p">(</span><span class="n">all_references</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span> <span class="k">if</span> <span class="n">all_references</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">micro_batch_labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">all_labels</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span> <span class="k">if</span> <span class="n">all_labels</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

            <span class="c1"># Build samples</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span><span class="p">:</span>
                <span class="n">sample</span><span class="p">,</span> <span class="n">updated_patch_idx</span><span class="p">,</span> <span class="n">updated_video_patch_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_unpacked_sample</span><span class="p">(</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="n">micro_batch_outputs</span><span class="p">,</span>
                    <span class="n">prompts</span><span class="o">=</span><span class="n">micro_batch_prompts</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">micro_batch_labels</span><span class="p">,</span>
                    <span class="n">references</span><span class="o">=</span><span class="n">micro_batch_references</span><span class="p">,</span>
                    <span class="n">is_multimodal</span><span class="o">=</span><span class="n">is_multimodal</span><span class="p">,</span>
                    <span class="n">grid_thw</span><span class="o">=</span><span class="n">micro_batch_grid_thw</span><span class="p">,</span>
                    <span class="n">video_grid_thw</span><span class="o">=</span><span class="n">micro_batch_video_grid_thw</span><span class="p">,</span>
                    <span class="n">raw_images</span><span class="o">=</span><span class="n">micro_batch_raw_images</span><span class="p">,</span>
                    <span class="n">pixel_values</span><span class="o">=</span><span class="n">all_images_pixel_values</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">pixel_values_videos</span><span class="o">=</span><span class="n">all_videos_pixel_values</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">images_num</span><span class="o">=</span><span class="n">all_images_num</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">videos_num</span><span class="o">=</span><span class="n">all_videos_num</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span><span class="p">]</span> <span class="k">if</span> <span class="n">is_multimodal</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">image_patch_idx</span><span class="o">=</span><span class="n">image_patch_idx</span><span class="p">,</span>
                    <span class="n">video_patch_idx</span><span class="o">=</span><span class="n">video_patch_idx</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="c1"># Update patch indices from the returned values</span>
                <span class="k">if</span> <span class="n">updated_patch_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">image_patch_idx</span> <span class="o">=</span> <span class="n">updated_patch_idx</span>
                <span class="k">if</span> <span class="n">updated_video_patch_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">video_patch_idx</span> <span class="o">=</span> <span class="n">updated_video_patch_idx</span>
                <span class="n">samples_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Packed samples</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_packed_sample</span><span class="p">(</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="n">micro_batch_outputs</span><span class="p">,</span>
                    <span class="n">prompts</span><span class="o">=</span><span class="n">micro_batch_prompts</span><span class="p">,</span>
                    <span class="n">labels</span><span class="o">=</span><span class="n">micro_batch_labels</span><span class="p">,</span>
                    <span class="n">references</span><span class="o">=</span><span class="n">micro_batch_references</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">samples_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="c1"># Report timing</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">gen_time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">get_current_device</span><span class="p">())</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">gen_time</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">MAX</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;***Rollout engine generation time (global max): </span><span class="si">{</span><span class="n">gen_time</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">report_memory</span><span class="p">(</span><span class="s2">&quot;after rollout engine generation&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">samples_list</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_advantages_and_returns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">rewards</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">action_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lambd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute advantages and returns using Generalized Advantage Estimation (GAE).</span>

<span class="sd">        Extends parent method with advantage whitening and clipping.</span>

<span class="sd">        :param values: Value estimates from critic</span>
<span class="sd">        :type values: torch.Tensor</span>
<span class="sd">        :param rewards: Reward signals</span>
<span class="sd">        :type rewards: torch.Tensor</span>
<span class="sd">        :param action_mask: Mask for valid action positions</span>
<span class="sd">        :type action_mask: torch.Tensor</span>
<span class="sd">        :param gamma: Discount factor</span>
<span class="sd">        :type gamma: float</span>
<span class="sd">        :param lambd: GAE lambda parameter</span>
<span class="sd">        :type lambd: float</span>
<span class="sd">        :return: Tuple of (advantages, returns, advantage_clip_fraction)</span>
<span class="sd">        :rtype: Tuple[torch.Tensor, torch.Tensor, float]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Call parent GAE implementation</span>
        <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_advantages_and_returns</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">action_mask</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">lambd</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>

        <span class="c1"># Advantage whitening (normalization)</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">advantages_norm</span><span class="p">:</span>
            <span class="n">masked_adv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">advantages</span><span class="p">,</span> <span class="n">action_mask</span><span class="p">)</span>
            <span class="n">adv_mean</span> <span class="o">=</span> <span class="n">masked_adv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">adv_std</span> <span class="o">=</span> <span class="n">masked_adv</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
            <span class="n">advantages</span> <span class="o">=</span> <span class="p">(</span><span class="n">advantages</span> <span class="o">-</span> <span class="n">adv_mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">adv_std</span> <span class="o">+</span> <span class="mf">1e-9</span><span class="p">)</span>

        <span class="c1"># Advantage clipping</span>
        <span class="n">advantage_clip_frac</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">advantage_clip</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">advantages</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">advantages</span><span class="p">,</span> <span class="o">-</span><span class="n">config</span><span class="o">.</span><span class="n">advantage_clip</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">advantage_clip</span><span class="p">)</span>
            <span class="n">advantage_clip_frac</span> <span class="o">=</span> <span class="n">compute_clip_fraction</span><span class="p">(</span><span class="n">advantages</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">advantage_clip</span><span class="p">,</span> <span class="o">-</span><span class="n">config</span><span class="o">.</span><span class="n">advantage_clip</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">advantages</span><span class="p">,</span> <span class="n">returns</span><span class="p">,</span> <span class="n">advantage_clip_frac</span>

    <span class="c1"># ========================================================================</span>
    <span class="c1"># Private Helper Methods</span>
    <span class="c1"># ========================================================================</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_process_multi_image_video_thws</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">experiences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">],</span>
        <span class="n">images_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">videos_num</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process image_grid_thws and video_grid_thws for multi-image/video scenarios.</span>

<span class="sd">        Ensures len(experience.sequences) == len(experience.image_grid_thws) by</span>
<span class="sd">        converting the stacked tensor into a list of per-sequence tensors.</span>

<span class="sd">        :param experiences: List of experiences to modify in-place</span>
<span class="sd">        :type experiences: List[ExperienceVL]</span>
<span class="sd">        :param images_num: Number of images per sample (expanded by n_samples_per_prompt)</span>
<span class="sd">        :type images_num: Optional[List[int]]</span>
<span class="sd">        :param videos_num: Number of videos per sample (expanded by n_samples_per_prompt)</span>
<span class="sd">        :type videos_num: Optional[List[int]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">experience</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">experiences</span><span class="p">):</span>
            <span class="c1"># Get image and video counts for this micro-batch</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">micro_rollout_batch_size</span>

            <span class="k">if</span> <span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">micro_images_num</span> <span class="o">=</span> <span class="n">images_num</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">micro_images_num</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">experience</span><span class="o">.</span><span class="n">image_grid_thws</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">image_grid_thw_list</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">image_grid_thws</span> <span class="o">=</span> <span class="n">experience</span><span class="o">.</span><span class="n">image_grid_thws</span>
                    <span class="n">image_grid_thws_unbind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">image_grid_thws</span><span class="p">)</span>

                    <span class="n">thw_idx</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">micro_images_num</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">stacked_thw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">image_grid_thws_unbind</span><span class="p">[</span><span class="n">thw_idx</span><span class="p">:</span><span class="n">thw_idx</span> <span class="o">+</span> <span class="n">num</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
                            <span class="n">image_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stacked_thw</span><span class="p">)</span>
                            <span class="n">thw_idx</span> <span class="o">+=</span> <span class="n">num</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">image_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                    <span class="n">experience</span><span class="o">.</span><span class="n">image_grid_thws</span> <span class="o">=</span> <span class="n">image_grid_thw_list</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">experience</span><span class="o">.</span><span class="n">image_grid_thws</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">micro_images_num</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">micro_videos_num</span> <span class="o">=</span> <span class="n">videos_num</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">micro_videos_num</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">experience</span><span class="o">.</span><span class="n">video_grid_thws</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">video_grid_thw_list</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">video_grid_thws</span> <span class="o">=</span> <span class="n">experience</span><span class="o">.</span><span class="n">video_grid_thws</span>
                    <span class="n">video_grid_thws_unbind</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="n">video_grid_thws</span><span class="p">)</span>

                    <span class="n">v_thw_idx</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">micro_videos_num</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">num</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">v_stacked_thw</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">video_grid_thws_unbind</span><span class="p">[</span><span class="n">v_thw_idx</span><span class="p">:</span><span class="n">v_thw_idx</span> <span class="o">+</span> <span class="n">num</span><span class="p">],</span>
                                                        <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
                            <span class="n">video_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v_stacked_thw</span><span class="p">)</span>
                            <span class="n">v_thw_idx</span> <span class="o">+=</span> <span class="n">num</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">video_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                    <span class="n">experience</span><span class="o">.</span><span class="n">video_grid_thws</span> <span class="o">=</span> <span class="n">video_grid_thw_list</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">experience</span><span class="o">.</span><span class="n">video_grid_thws</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">micro_videos_num</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_process_experiences</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">experiences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">],</span>
        <span class="n">max_new_tokens</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply reward transformations and filtering to experiences.</span>

<span class="sd">        Handles:</span>
<span class="sd">            - Overlong sequence penalty</span>
<span class="sd">            - Dynamic sampling filtering</span>
<span class="sd">            - Advantage estimation-specific reward shaping (RLOO, REINFORCE, Group Norm)</span>

<span class="sd">        :param experiences: List of experiences to process</span>
<span class="sd">        :type experiences: List[Union[Experience, ExperienceVL]]</span>
<span class="sd">        :param max_new_tokens: Maximum generation length</span>
<span class="sd">        :type max_new_tokens: int</span>
<span class="sd">        :return: Tuple of (processed_experiences, shaped_rewards)</span>
<span class="sd">        :rtype: Tuple[List[Union[Experience, ExperienceVL]], List[torch.Tensor]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">exp</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;reward&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">experiences</span><span class="p">])</span>

        <span class="c1"># ========== Overlong Sequence Penalty ==========</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">overlong_buffer</span><span class="p">:</span>
            <span class="n">expected_len</span> <span class="o">=</span> <span class="n">max_new_tokens</span> <span class="o">-</span> <span class="n">config</span><span class="o">.</span><span class="n">overlong_buffer_len</span>
            <span class="n">actual_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">exp</span><span class="o">.</span><span class="n">action_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">experiences</span><span class="p">])</span>
            <span class="n">exceed_len</span> <span class="o">=</span> <span class="n">actual_lens</span> <span class="o">-</span> <span class="n">expected_len</span>

            <span class="c1"># Penalty: clamp(-exceed_len / buffer_len * penalty_factor, max=0)</span>
            <span class="n">penalty</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                <span class="o">-</span><span class="n">exceed_len</span> <span class="o">/</span> <span class="n">config</span><span class="o">.</span><span class="n">overlong_buffer_len</span> <span class="o">*</span> <span class="n">config</span><span class="o">.</span><span class="n">overlong_buffer_penalty_factor</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="p">)</span>
            <span class="n">rewards</span> <span class="o">+=</span> <span class="n">penalty</span>

        <span class="c1"># ========== Dynamic Sampling Warning ==========</span>
        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">dynamic_sampling</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">advantage_estimator</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;rloo&quot;</span><span class="p">,</span> <span class="s2">&quot;reinforce_baseline&quot;</span><span class="p">]:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dynamic_sampling not implemented for </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">advantage_estimator</span><span class="si">}</span><span class="s2">, ignoring&quot;</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">)</span>

        <span class="c1"># ========== Advantage Estimator-Specific Shaping ==========</span>
        <span class="c1"># Use calculator&#39;s preprocess_rewards method</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">advantage_calculator</span><span class="o">.</span><span class="n">preprocess_rewards</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">experiences</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_advantages_and_returns</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">experiences</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">],</span>
        <span class="n">rewards</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">generate_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ExperienceVL</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute advantages and returns for each experience.</span>

<span class="sd">        Applies reward normalization/clipping, KL penalty, and advantage estimation</span>
<span class="sd">        based on the configured method (GAE, CPGD, REINFORCE, etc.).</span>

<span class="sd">        :param experiences: List of experiences to process</span>
<span class="sd">        :type experiences: List[Union[Experience, ExperienceVL]]</span>
<span class="sd">        :param rewards: List of reward tensors</span>
<span class="sd">        :type rewards: List[torch.Tensor]</span>
<span class="sd">        :param generate_kwargs: Generation parameters (contains gamma, lambd)</span>
<span class="sd">        :type generate_kwargs: Dict</span>
<span class="sd">        :return: List of experiences with advantages and returns filled in</span>
<span class="sd">        :rtype: List[Union[Experience, ExperienceVL]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">config</span>

        <span class="k">for</span> <span class="n">experience</span><span class="p">,</span> <span class="n">reward</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="n">rewards</span><span class="p">):</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="n">processed_reward</span> <span class="o">=</span> <span class="n">reward</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># TODOcheck</span>

            <span class="c1"># ========== Reward Normalization ==========</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">processed_reward</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_running_norm_minus_mean</span><span class="p">:</span>
                    <span class="n">processed_reward</span> <span class="o">=</span> <span class="p">((</span><span class="n">processed_reward</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span><span class="o">.</span><span class="n">std</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">processed_reward</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_running_moments</span><span class="o">.</span><span class="n">std</span>

            <span class="c1"># ========== Reward Clipping ==========</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_clip</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;reward_clip_frac&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_clip_fraction</span><span class="p">(</span>
                    <span class="n">processed_reward</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_clip</span><span class="p">,</span> <span class="o">-</span><span class="n">config</span><span class="o">.</span><span class="n">reward_clip</span>
                <span class="p">)</span>
                <span class="n">processed_reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">processed_reward</span><span class="p">,</span> <span class="o">-</span><span class="n">config</span><span class="o">.</span><span class="n">reward_clip</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">reward_clip</span><span class="p">)</span>

            <span class="c1"># ========== Final Reward (with KL penalty) ==========</span>
            <span class="n">final_reward</span> <span class="o">=</span> <span class="n">compute_reward</span><span class="p">(</span>
                <span class="n">processed_reward</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">kl_ctl</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">experience</span><span class="o">.</span><span class="n">kl</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">experience</span><span class="o">.</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">num_actions</span><span class="o">=</span><span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;num_actions&quot;</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># ========== Advantage Estimation ==========</span>
            <span class="c1"># Compute advantages and returns using calculator</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="n">generate_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">experience</span><span class="o">.</span><span class="n">advantages</span><span class="p">,</span> <span class="n">experience</span><span class="o">.</span><span class="n">returns</span><span class="p">,</span> <span class="n">info_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">advantage_calculator</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span>
                <span class="n">experience</span><span class="p">,</span>
                <span class="n">final_reward</span><span class="p">,</span>
                <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
                <span class="n">generate_kwargs</span><span class="o">=</span><span class="n">generate_kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Update experience info with calculator&#39;s info dict</span>
            <span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">info_dict</span><span class="p">)</span>

            <span class="c1"># ========== Store Episode Return ==========</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span><span class="p">:</span>
                <span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;return&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_reward</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;return&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">r</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">final_reward</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">final_reward</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Cleanup</span>
            <span class="n">experience</span><span class="o">.</span><span class="n">kl</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">del</span> <span class="n">experience</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;num_actions&quot;</span><span class="p">]</span>

        <span class="c1"># ========== Cross-batch Advantage Normalization ==========</span>
        <span class="c1"># Use the utility function for cross-batch normalization</span>
        <span class="n">experiences</span> <span class="o">=</span> <span class="n">normalize_advantages_cross_batch</span><span class="p">(</span><span class="n">experiences</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">advantage_estimator</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">experiences</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_make_experience_list_by_model</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">all_samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Samples</span><span class="p">,</span> <span class="n">SamplesVL</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Experience</span><span class="p">,</span> <span class="n">ExperienceVL</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Batch forward pass through all models to create experiences.</span>

<span class="sd">        This method implements role-based batching to avoid frequent model switching.</span>
<span class="sd">        Processing order:</span>
<span class="sd">            1. Actor (log probabilities)</span>
<span class="sd">            2. Initial model (reference log probabilities)</span>
<span class="sd">            3. Critic (value estimates)</span>
<span class="sd">            4. Reward model(s) (rewards)</span>
<span class="sd">            5. Assemble Experience objects</span>

<span class="sd">        :param all_samples: List of Samples/SamplesVL from generate_samples</span>
<span class="sd">        :type all_samples: List[Union[Samples, SamplesVL]]</span>
<span class="sd">        :return: List of Experience/ExperienceVL objects with model outputs filled in</span>
<span class="sd">        :rtype: List[Union[Experience, ExperienceVL]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">get_current_device</span><span class="p">()</span>
        <span class="n">vlm_mode</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">all_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">SamplesVL</span><span class="p">)</span>

        <span class="c1"># ========== Stage 0: Preprocessing ==========</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_preprocess_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">all_samples</span><span class="p">]</span>

        <span class="c1"># ========== Stage 1: Actor Forward ==========</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;    actor_logprob&#39;</span><span class="p">)</span>
        <span class="c1"># Check if we need to compute entropy for high-entropy token filtering</span>
        <span class="n">need_entropy</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">,</span> <span class="s1">&#39;high_entropy_token_ratio&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">high_entropy_token_ratio</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">need_entropy</span><span class="p">:</span>
                <span class="c1"># Request full output to get action_entropy</span>
                <span class="n">action_log_probs</span><span class="p">,</span> <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                    <span class="n">packed_seq_lens</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">,</span>
                    <span class="n">return_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">output</span><span class="o">.</span><span class="n">inputs_extra_kwargs</span>
                <span class="p">)</span>
                <span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span> <span class="o">=</span> <span class="n">action_log_probs</span>
                <span class="c1"># Extract action_entropy if available</span>
                <span class="k">if</span> <span class="s2">&quot;action_entropy&quot;</span> <span class="ow">in</span> <span class="n">model_output</span><span class="p">:</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">action_entropy</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[</span><span class="s2">&quot;action_entropy&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                    <span class="n">packed_seq_lens</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">output</span><span class="o">.</span><span class="n">inputs_extra_kwargs</span>
                <span class="p">)</span>
        <span class="n">Timer</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="s1">&#39;    actor_logprob&#39;</span><span class="p">)</span>

        <span class="c1"># ========== Stage 2: Initial Model ==========</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reload_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_model</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">base_action_log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_model</span><span class="p">(</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                    <span class="n">packed_seq_lens</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">packed_seq_lens</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">output</span><span class="o">.</span><span class="n">inputs_extra_kwargs</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">offload_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_model</span><span class="p">)</span>

        <span class="c1"># ========== Stage 3: Critic ==========</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">reload_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
                <span class="n">output</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="p">(</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">output</span><span class="o">.</span><span class="n">inputs_extra_kwargs</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">offload_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">critic</span><span class="p">)</span>

        <span class="c1"># ========== Stage 4: Reward Models ==========</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_engine</span><span class="o">.</span><span class="n">compute_rewards</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

        <span class="c1"># ========== Stage 5: Assemble Experiences ==========</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_pack_experience</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">vlm_mode</span><span class="p">)</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_preprocess_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sample</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Samples</span><span class="p">,</span> <span class="n">SamplesVL</span><span class="p">],</span>
        <span class="n">vlm</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_SamplesOutput</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert a Samples object to _SamplesOutput for processing.</span>

<span class="sd">        :param sample: Input sample</span>
<span class="sd">        :type sample: Union[Samples, SamplesVL]</span>
<span class="sd">        :param vlm: Vision-language mode flag</span>
<span class="sd">        :type vlm: bool</span>
<span class="sd">        :param device: Target device</span>
<span class="sd">        :type device: torch.device</span>
<span class="sd">        :return: _SamplesOutput with data ready for model inference</span>
<span class="sd">        :rtype: _SamplesOutput</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract common fields</span>
        <span class="n">sequences</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">sequences</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">action_mask</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">action_mask</span>
        <span class="n">num_actions</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">num_actions</span>
        <span class="n">packed_seq_lens</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">packed_seq_lens</span>
        <span class="n">response_length</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">response_length</span>
        <span class="n">total_length</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">total_length</span>
        <span class="n">prompts</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">prompts</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">references</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">references</span>
        <span class="n">output_texts</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;output_texts&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Build extra kwargs for VLM based on actor&#39;s modality</span>
        <span class="c1"># Only include parameters that the actor&#39;s modality supports</span>
        <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">vlm</span><span class="p">:</span>
            <span class="c1"># Candidate parameters to pass</span>
            <span class="n">candidate_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;pixel_values&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">pixel_values</span><span class="p">,</span>
                <span class="s2">&quot;image_grid_thw&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">image_grid_thws</span><span class="p">,</span>
                <span class="s2">&quot;pixel_values_videos&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">pixel_values_videos</span><span class="p">,</span>
                <span class="s2">&quot;video_grid_thw&quot;</span><span class="p">:</span> <span class="n">sample</span><span class="o">.</span><span class="n">video_grid_thws</span><span class="p">,</span>
            <span class="p">}</span>

            <span class="c1"># Filter to only include supported parameters</span>
            <span class="n">extra_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">candidate_params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_actor_supported_params</span>
            <span class="p">}</span>

        <span class="c1"># Fix Qwen-VL image token count bug</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fix_qwen_vl_image_tokens</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">sample</span><span class="p">,</span> <span class="n">vlm</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">_SamplesOutput</span><span class="p">(</span>
            <span class="n">sequences</span><span class="o">=</span><span class="n">sequences</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">action_mask</span><span class="o">=</span><span class="n">action_mask</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">packed_seq_lens</span><span class="o">=</span><span class="n">packed_seq_lens</span><span class="p">,</span>
            <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
            <span class="n">total_length</span><span class="o">=</span><span class="n">total_length</span><span class="p">,</span>
            <span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">pixel_values</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;pixel_values&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">image_grid_thw</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;image_grid_thws&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">pixel_values_videos</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;pixel_values_videos&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">video_grid_thw</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;video_grid_thws&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">raw_images</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;raw_images&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">image_num</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;image_num&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">video_num</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="s2">&quot;video_num&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
            <span class="n">inputs_extra_kwargs</span><span class="o">=</span><span class="n">extra_kwargs</span><span class="p">,</span>
            <span class="n">prompt_and_output</span><span class="o">=</span><span class="p">([</span><span class="n">p</span> <span class="o">+</span> <span class="p">(</span><span class="n">o</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">output_texts</span><span class="p">)]</span> <span class="k">if</span> <span class="n">output_texts</span> <span class="k">else</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_fix_qwen_vl_image_tokens</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sequences</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">sample</span><span class="p">:</span> <span class="n">SamplesVL</span><span class="p">,</span>
        <span class="n">vlm</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fix Qwen-VL image token count mismatch.</span>

<span class="sd">        In some cases, the number of image tokens in sequences doesn&#39;t match</span>
<span class="sd">        the number of pixel value patches. This fixes the discrepancy by replacing</span>
<span class="sd">        extra image tokens with padding tokens.</span>

<span class="sd">        :param sequences: Token sequence (modified in-place)</span>
<span class="sd">        :type sequences: torch.Tensor</span>
<span class="sd">        :param sample: Original sample</span>
<span class="sd">        :type sample: SamplesVL</span>
<span class="sd">        :param vlm: Vision-language mode flag</span>
<span class="sd">        :type vlm: bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">vlm</span> <span class="ow">or</span> <span class="n">sample</span><span class="o">.</span><span class="n">pixel_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">unwrap_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">config</span>
        <span class="n">image_token_id</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">image_token_id</span>
        <span class="n">num_tokens</span> <span class="o">=</span> <span class="p">(</span><span class="n">sequences</span> <span class="o">==</span> <span class="n">image_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">num_patches</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">pixel_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>

        <span class="k">if</span> <span class="n">num_tokens</span> <span class="o">!=</span> <span class="n">num_patches</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;[Warning] Mismatch found during rollout step. Fixing sequences. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Tokens: </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="s2">, Patches: </span><span class="si">{</span><span class="n">num_patches</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">num_tokens</span> <span class="o">-</span> <span class="n">num_patches</span>
            <span class="n">token_positions</span> <span class="o">=</span> <span class="p">(</span><span class="n">sequences</span> <span class="o">==</span> <span class="n">image_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>

            <span class="c1"># Replace extra tokens from the end</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">diff</span><span class="p">):</span>
                <span class="n">pos</span> <span class="o">=</span> <span class="n">token_positions</span><span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="n">sequences</span><span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pad_token_id</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_pack_experience</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">output</span><span class="p">:</span> <span class="n">_SamplesOutput</span><span class="p">,</span>
        <span class="n">vlm</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Experience</span><span class="p">,</span> <span class="n">ExperienceVL</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pack model outputs into an Experience object.</span>

<span class="sd">        :param output: Processed sample output</span>
<span class="sd">        :type output: _SamplesOutput</span>
<span class="sd">        :param vlm: Vision-language mode flag</span>
<span class="sd">        :type vlm: bool</span>
<span class="sd">        :return: Experience or ExperienceVL object</span>
<span class="sd">        :rtype: Union[Experience, ExperienceVL]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Compute KL divergence</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">use_kl_loss</span><span class="p">:</span>
            <span class="c1"># Note: When use_kl_loss is True, KL is used as a loss term;</span>
            <span class="c1"># when False, KL is added to reward as augmentation</span>
            <span class="n">kl</span> <span class="o">=</span> <span class="n">compute_approx_kl</span><span class="p">(</span>
                <span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span><span class="p">,</span>
                <span class="n">output</span><span class="o">.</span><span class="n">base_action_log_probs</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">kl_estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">kl_estimator</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span><span class="p">)</span>

        <span class="c1"># Compute mean KL</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">packing_samples</span><span class="p">:</span>
            <span class="n">kl_mean</span> <span class="o">=</span> <span class="n">masked_mean</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">action_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kl_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="p">[</span><span class="n">each</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">unpacking_samples</span><span class="p">(</span><span class="n">kl</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">)],</span>
                <span class="n">device</span><span class="o">=</span><span class="n">kl</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Clear base log probs if not needed</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategy</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">use_kl_loss</span><span class="p">:</span>
            <span class="n">output</span><span class="o">.</span><span class="n">base_action_log_probs</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Build info dict</span>
        <span class="n">info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">kl</span><span class="o">=</span><span class="n">kl_mean</span><span class="p">,</span>
            <span class="n">reward</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span>
            <span class="n">response_length</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">response_length</span><span class="p">,</span>
            <span class="n">total_length</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">total_length</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">num_actions</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Add reward_metrics if available</span>
        <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">reward_metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">info</span><span class="p">[</span><span class="s1">&#39;reward_metrics&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">reward_metrics</span>

        <span class="c1"># Create Experience object</span>
        <span class="k">if</span> <span class="n">vlm</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ExperienceVL</span><span class="p">(</span>
                <span class="n">sequences</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span>
                <span class="n">pixel_values</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">pixel_values</span><span class="p">,</span>
                <span class="n">image_grid_thws</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">image_grid_thw</span><span class="p">,</span>
                <span class="n">raw_images</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">raw_images</span><span class="p">,</span>
                <span class="n">pixel_values_videos</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">pixel_values_videos</span><span class="p">,</span>
                <span class="n">video_grid_thws</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">video_grid_thw</span><span class="p">,</span>
                <span class="n">action_log_probs</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span><span class="p">,</span>
                <span class="n">base_action_log_probs</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">base_action_log_probs</span><span class="p">,</span>
                <span class="n">values</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">returns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># returns (filled later)</span>
                <span class="n">advantages</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># advantages (filled later)</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span>
                <span class="n">kl</span><span class="o">=</span><span class="n">kl</span><span class="p">,</span>
                <span class="n">action_entropy</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_entropy</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Experience</span><span class="p">(</span>
                <span class="n">sequences</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">,</span>
                <span class="n">action_log_probs</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_log_probs</span><span class="p">,</span>
                <span class="n">base_action_log_probs</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">base_action_log_probs</span><span class="p">,</span>
                <span class="n">values</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                <span class="n">returns</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># returns (filled later)</span>
                <span class="n">advantages</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># advantages (filled later)</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">,</span>
                <span class="n">kl</span><span class="o">=</span><span class="n">kl</span><span class="p">,</span>
                <span class="n">action_entropy</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">action_entropy</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_unpacked_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
        <span class="n">references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
        <span class="n">is_multimodal</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Samples</span><span class="p">,</span> <span class="n">SamplesVL</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build unpacked sample (one sequence per row with padding).</span>

<span class="sd">        Sample format:</span>
<span class="sd">        | [PAD] [PAD] prompt_token ... | response_token ... [EOS] [PAD] |</span>

<span class="sd">        :param outputs: Engine outputs</span>
<span class="sd">        :type outputs: List</span>
<span class="sd">        :param prompts: Text prompts</span>
<span class="sd">        :type prompts: List[str]</span>
<span class="sd">        :param labels: Sample labels</span>
<span class="sd">        :type labels: Optional[List]</span>
<span class="sd">        :param references: Reference texts</span>
<span class="sd">        :type references: Optional[List]</span>
<span class="sd">        :param is_multimodal: Whether in VLM mode</span>
<span class="sd">        :type is_multimodal: bool</span>
<span class="sd">        :param kwargs: Additional VLM-specific arguments</span>
<span class="sd">        :type kwargs: dict</span>
<span class="sd">        :return: Tuple of (Samples/SamplesVL object, updated image_patch_idx, updated video_patch_idx)</span>
<span class="sd">        :rtype: Tuple[Union[Samples, SamplesVL], Optional[int], Optional[int]]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Find max lengths</span>
        <span class="n">max_input_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="n">max_output_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">)</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="n">pad_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
        <span class="n">eos_token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span>

        <span class="n">sequences</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_output_ids</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># VLM data structures</span>
        <span class="k">if</span> <span class="n">is_multimodal</span><span class="p">:</span>
            <span class="n">pixel_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">image_grid_thw_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">all_img_num</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">pixel_values_videos</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">video_grid_thw_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">all_vid_num</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">grid_thw</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;grid_thw&quot;</span><span class="p">]</span>
            <span class="n">raw_images</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;raw_images&quot;</span><span class="p">]</span>
            <span class="n">pixel_values_tensor</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;pixel_values&quot;</span><span class="p">]</span>
            <span class="n">images_num</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;images_num&quot;</span><span class="p">]</span>
            <span class="n">image_patch_idx</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;image_patch_idx&quot;</span><span class="p">]</span>

            <span class="n">video_grid_thw</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;video_grid_thw&quot;</span><span class="p">]</span>
            <span class="n">pixel_values_videos_tensor</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;pixel_values_videos&quot;</span><span class="p">]</span>
            <span class="n">videos_num</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;videos_num&quot;</span><span class="p">]</span>
            <span class="n">video_patch_idx</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;video_patch_idx&quot;</span><span class="p">]</span>

            <span class="n">local_grid_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">local_video_grid_idx</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Process each output</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
            <span class="c1"># Left-pad input</span>
            <span class="n">input_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">)</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">pad_token_id</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_input_len</span> <span class="o">-</span> <span class="n">input_len</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">)</span>

            <span class="c1"># Right-pad output</span>
            <span class="n">output_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">)</span>
            <span class="n">output_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_token_id</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_output_len</span> <span class="o">-</span> <span class="n">output_len</span><span class="p">)</span>
            <span class="n">all_output_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">)</span>

            <span class="c1"># Process images/videos for this sample</span>
            <span class="k">if</span> <span class="n">is_multimodal</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">images_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">image_num</span> <span class="o">=</span> <span class="n">images_num</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">all_img_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_num</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">img_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">image_num</span><span class="p">):</span>
                        <span class="n">grid</span> <span class="o">=</span> <span class="n">grid_thw</span><span class="p">[</span><span class="n">local_grid_idx</span> <span class="o">+</span> <span class="n">img_idx</span><span class="p">]</span>
                        <span class="n">num_patch</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">grid</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                        <span class="n">image_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

                        <span class="k">if</span> <span class="n">num_patch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">pixel_slice</span> <span class="o">=</span> <span class="n">pixel_values_tensor</span><span class="p">[</span><span class="n">image_patch_idx</span><span class="p">:</span><span class="n">image_patch_idx</span> <span class="o">+</span> <span class="n">num_patch</span><span class="p">]</span>
                            <span class="n">pixel_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pixel_slice</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                        <span class="n">image_patch_idx</span> <span class="o">+=</span> <span class="n">num_patch</span>

                    <span class="n">local_grid_idx</span> <span class="o">+=</span> <span class="n">image_num</span>

                <span class="k">if</span> <span class="n">videos_num</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">video_num</span> <span class="o">=</span> <span class="n">videos_num</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                    <span class="n">all_vid_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">video_num</span><span class="p">)</span>

                    <span class="k">for</span> <span class="n">vid_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">video_num</span><span class="p">):</span>
                        <span class="n">grid</span> <span class="o">=</span> <span class="n">video_grid_thw</span><span class="p">[</span><span class="n">local_video_grid_idx</span> <span class="o">+</span> <span class="n">vid_idx</span><span class="p">]</span>
                        <span class="n">num_patch</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">grid</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                        <span class="n">video_grid_thw_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

                        <span class="k">if</span> <span class="n">num_patch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">pixel_slice</span> <span class="o">=</span> <span class="n">pixel_values_videos_tensor</span><span class="p">[</span><span class="n">video_patch_idx</span><span class="p">:</span><span class="n">video_patch_idx</span> <span class="o">+</span> <span class="n">num_patch</span><span class="p">]</span>
                            <span class="n">pixel_values_videos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pixel_slice</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
                        <span class="n">video_patch_idx</span> <span class="o">+=</span> <span class="n">num_patch</span>

                    <span class="n">local_video_grid_idx</span> <span class="o">+=</span> <span class="n">video_num</span>  <span class="c1"># Concatenate input and output</span>
            <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">+</span> <span class="n">output_ids</span><span class="p">)</span>

        <span class="c1"># Decode output texts</span>
        <span class="n">output_texts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">all_output_ids</span><span class="p">)</span>

        <span class="c1"># Process sequences</span>
        <span class="n">sequences</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
        <span class="n">sequences</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">action_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">process_sequences</span><span class="p">(</span>
            <span class="n">sequences</span><span class="p">,</span> <span class="n">max_input_len</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="p">,</span> <span class="n">pad_token_id</span>
        <span class="p">)</span>
        <span class="n">sequences</span> <span class="o">=</span> <span class="n">sequences</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="n">action_mask</span> <span class="o">=</span> <span class="n">action_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_multimodal</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Samples</span><span class="p">(</span>
                <span class="n">sequences</span><span class="o">=</span><span class="n">sequences</span><span class="p">,</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">num_actions</span><span class="o">=</span><span class="n">action_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">packed_seq_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">response_length</span><span class="o">=</span><span class="n">action_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">total_length</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
                <span class="n">pad_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">),</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>  <span class="c1"># Return None for patch indices</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Process VLM pixel values</span>
            <span class="n">pixel_values</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="n">pixel_values</span> <span class="ow">and</span> <span class="n">pixel_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="n">pixel_values_videos</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pixel_values_videos</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">pixel_values_videos</span> <span class="ow">and</span> <span class="n">pixel_values_videos</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">SamplesVL</span><span class="p">(</span>
                <span class="n">sequences</span><span class="o">=</span><span class="n">sequences</span><span class="p">,</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
                <span class="n">action_mask</span><span class="o">=</span><span class="n">action_mask</span><span class="p">,</span>
                <span class="n">image_grid_thws</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">image_grid_thw_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">image_grid_thw_list</span> <span class="k">else</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">video_grid_thws</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">video_grid_thw_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">video_grid_thw_list</span> <span class="k">else</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">raw_images</span><span class="o">=</span><span class="n">raw_images</span><span class="p">,</span>
                <span class="n">pixel_values</span><span class="o">=</span><span class="n">pixel_values</span><span class="p">,</span>
                <span class="n">pixel_values_videos</span><span class="o">=</span><span class="n">pixel_values_videos</span><span class="p">,</span>
                <span class="n">num_actions</span><span class="o">=</span><span class="n">action_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">packed_seq_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">response_length</span><span class="o">=</span><span class="n">action_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">total_length</span><span class="o">=</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
                <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                <span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
                <span class="n">output_texts</span><span class="o">=</span><span class="n">output_texts</span><span class="p">,</span>
                <span class="n">image_num</span><span class="o">=</span><span class="n">all_img_num</span><span class="p">,</span>
                <span class="n">video_num</span><span class="o">=</span><span class="n">all_vid_num</span><span class="p">,</span>
            <span class="p">),</span> <span class="n">image_patch_idx</span><span class="p">,</span> <span class="n">video_patch_idx</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_packed_sample</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">prompts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
        <span class="n">references</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Samples</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build packed sample (multiple sequences concatenated without padding).</span>

<span class="sd">        Sample format:</span>
<span class="sd">        | prompt1 response1 [EOS] | prompt2 response2 [EOS] | prompt3 ... |</span>

<span class="sd">        :param outputs: Engine outputs</span>
<span class="sd">        :type outputs: List</span>
<span class="sd">        :param prompts: Text prompts</span>
<span class="sd">        :type prompts: List[str]</span>
<span class="sd">        :param labels: Sample labels</span>
<span class="sd">        :type labels: Optional[List]</span>
<span class="sd">        :param references: Reference texts</span>
<span class="sd">        :type references: Optional[List]</span>
<span class="sd">        :return: Samples object with packed sequences</span>
<span class="sd">        :rtype: Samples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sequences</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">packed_seq_lens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">num_actions</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
            <span class="n">input_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span><span class="p">)</span>
            <span class="n">output_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">)</span>
            <span class="n">packed_seq_lens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_len</span> <span class="o">+</span> <span class="n">output_len</span><span class="p">)</span>

            <span class="n">sequences</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">prompt_token_ids</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">output_token_ids</span><span class="p">))</span>
            <span class="n">attention_mask</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_len</span> <span class="o">+</span> <span class="n">output_len</span><span class="p">))</span>
            <span class="n">num_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_len</span><span class="p">))</span>

        <span class="n">sequences</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">response_length</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="n">total_length</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">packed_seq_lens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Samples</span><span class="p">(</span>
            <span class="n">sequences</span><span class="o">=</span><span class="n">sequences</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">action_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_actions</span><span class="o">=</span><span class="n">num_actions</span><span class="p">,</span>
            <span class="n">packed_seq_lens</span><span class="o">=</span><span class="n">packed_seq_lens</span><span class="p">,</span>
            <span class="n">response_length</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
            <span class="n">total_length</span><span class="o">=</span><span class="n">total_length</span><span class="p">,</span>
            <span class="n">prompts</span><span class="o">=</span><span class="n">prompts</span><span class="p">,</span>
            <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
            <span class="n">references</span><span class="o">=</span><span class="n">references</span><span class="p">,</span>
            <span class="n">pad_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span></div>
</pre></div>

              </article>
              
            </div>
            <footer>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2025, OpenDILab.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../../../"
    src="../../../_static/documentation_options.js"></script>
  <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
  <script src="../../../_static/doctools.js"></script>
  <script src="../../../_static/sphinx_highlight.js"></script>
  <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
  <script src="../../../_static/js/language_switch.js"></script>
  

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/LightRFT" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>